{"cells":[{"cell_type":"markdown","id":"5cefac89","metadata":{"id":"5cefac89"},"source":["# Finetuning Whisper-large-V2 on Colab using PEFT-Lora + BNB INT8 training"]},{"cell_type":"markdown","id":"090fa3ed","metadata":{"id":"090fa3ed"},"source":["In this Colab, we present a step-by-step guide on how to fine-tune Whisper for any multilingual ASR dataset using Hugging Face 🤗 Transformers and 🤗 PEFT. Using 🤗 PEFT and `bitsandbytes`, you can train the `whisper-large-v2` seamlessly on a colab with T4 GPU (16 GB VRAM). In this notebook, with most parts from [fine_tune_whisper.ipynb](https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb#scrollTo=BRdrdFIeU78w) is adapted to train using PEFT LoRA+BNB INT8.\n","\n","For more details on model, datasets and metrics, refer blog [Fine-Tune Whisper For Multilingual ASR with 🤗 Transformers](https://huggingface.co/blog/fine-tune-whisper)\n","\n"]},{"cell_type":"markdown","id":"625e47a0","metadata":{"id":"625e47a0"},"source":["## Inital Setup"]},{"cell_type":"code","execution_count":null,"id":"eJrPyQM5Xhv5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12289,"status":"ok","timestamp":1704836380299,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"eJrPyQM5Xhv5","outputId":"b1e69368-6194-424e-cbfb-fb369362e61e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Repository: 'deb https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu/ jammy main'\n","Description:\n","Backport of FFmpeg 4 and associated libraries. Now includes AOM/AV1 support!\n","\n","FDK AAC is not compatible with GPL and FFmpeg can't be redistributed with it included. Please don't ask for it to be added to this public PPA.\n","\n","---\n","\n","PPA supporters:\n","\n","BigBlueButton (https://bigbluebutton.org)\n","\n","---\n","\n","Donate to FFMPEG: https://ffmpeg.org/donations.html\n","Donate to Debian: https://www.debian.org/donations\n","Donate to this PPA: https://ko-fi.com/jonathonf\n","More info: https://launchpad.net/~jonathonf/+archive/ubuntu/ffmpeg-4\n","Adding repository.\n","Adding deb entry to /etc/apt/sources.list.d/jonathonf-ubuntu-ffmpeg-4-jammy.list\n","Adding disabled deb-src entry to /etc/apt/sources.list.d/jonathonf-ubuntu-ffmpeg-4-jammy.list\n","Adding key to /etc/apt/trusted.gpg.d/jonathonf-ubuntu-ffmpeg-4.gpg with fingerprint 4AB0F789CBA31744CC7DA76A8CF63AD3F06FC659\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,335 kB]\n","Ign:10 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Err:13 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release\n","  404  Not Found [IP: 185.125.190.80 443]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,614 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.6 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,047 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,586 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,308 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [50.4 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,606 kB]\n","Reading package lists... Done\n","E: The repository 'https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release' does not have a Release file.\n","N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n","N: See apt-secure(8) manpage for repository creation and user configuration details.\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Ign:10 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Err:12 https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release\n","  404  Not Found [IP: 185.125.190.80 443]\n","Reading package lists... Done\n","\u001b[1;31mE: \u001b[0mThe repository 'https://ppa.launchpadcontent.net/jonathonf/ffmpeg-4/ubuntu jammy Release' does not have a Release file.\u001b[0m\n","\u001b[33mN: \u001b[0mUpdating from such a repository can't be done securely, and is therefore disabled by default.\u001b[0m\n","\u001b[33mN: \u001b[0mSee apt-secure(8) manpage for repository creation and user configuration details.\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"]}],"source":["!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n","!apt update\n","!apt install -y ffmpeg"]},{"cell_type":"code","execution_count":null,"id":"r_Ivl7qlX0dz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119944,"status":"ok","timestamp":1704852902342,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"r_Ivl7qlX0dz","outputId":"37cdc345-e22d-4060-8fe1-546d5c2a1d89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-yfb501vx\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-yfb501vx\n","  Resolved https://github.com/huggingface/transformers to commit 976189a6df796a2ff442dd81b022626c840d8c27\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2023.11.17)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8342965 sha256=9590537959909ff61a9df7e57aa600dca184b931adca50ef9e402fb0e5a52fdb\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-76rwu0sq/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","Successfully installed transformers-4.37.0.dev0\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n","Collecting jiwer\n","  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n","Successfully installed jiwer-3.0.3 rapidfuzz-3.6.1\n","Collecting gradio\n","  Downloading gradio-4.13.0-py3-none-any.whl (16.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.8.0 (from gradio)\n","  Downloading gradio_client-0.8.0-py3-none-any.whl (305 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.2)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Collecting pydantic>=2.0 (from gradio)\n","  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.0->gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n","Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n","  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n","Collecting pydantic-core==2.14.6 (from pydantic>=2.0->gradio)\n","  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n","  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.33.0,>=0.29.0 (from fastapi->gradio)\n","  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n","Collecting httpcore==1.* (from httpx->gradio)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=72021497d335602e50ae7b5cf78d398776f597afe53d7589396d20de061fe42e\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.13\n","    Uninstalling pydantic-1.10.13:\n","      Successfully uninstalled pydantic-1.10.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.108.0 ffmpy-0.3.1 gradio-4.13.0 gradio-client-0.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 orjson-3.9.10 pydantic-2.5.3 pydantic-core-2.14.6 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.32.0.post1 tomlkit-0.12.0 typing-extensions-4.9.0 uvicorn-0.25.0 websockets-11.0.3\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install datasets>=2.6.1\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install librosa\n","!pip install evaluate>=0.30\n","!pip install jiwer\n","!pip install gradio\n","!pip install -q bitsandbytes datasets accelerate loralib\n","!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git@main"]},{"cell_type":"markdown","id":"8a528c1a","metadata":{"id":"8a528c1a"},"source":["Linking the notebook to the Hub is straightforward - it simply requires entering your Hub authentication token when prompted. Find your Hub authentication token [here](https://huggingface.co/settings/tokens):"]},{"cell_type":"code","execution_count":null,"id":"ed0OpduhX2JF","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160,"referenced_widgets":["089eb6a360d3461e96d696c686b29b05","38efbda33170462988008da40974bb38","8f1fd636e20246c2bf8e147b1cea750d","278a72b8f46441149fbc04dd7dfe9eaa","7ce05b0030c149edbd214e85302f51bb","b0be6b32664a48d683a70bef051c4913","f79021fd9e8c40d99bb10c3fe025f4ba","b9ed46b759e24d1b8d16e03ed6873e77","fa6fb1445752440487816a1ebd3398a6","ae4f94c1b36a4150b3f6bbf2c951febc","3f630911735946f0854eee7777340c1f","5284cbf6f5344dc9a059e66009da2c8d","2718ed0370cd497a8a55ed90e87865fe","f320bc899b3e4a8e97797834939ffa7d","2a30f66860354787b938f061b71607e1","8e43d3ba53b141a0a1f0ede60171f0c1","882d0c484b504dd8b81a838ecba2a0d8","f1c985a5eb19488ba265cf85ab24307b","b8fb7b52e9bf4b5b989dfb8cff8c09b6","772dd409ba634e01985bd48c83660dac","cf5a1711cdb34cbd9905a7c615d0c44f","9f079f19acaf44fabba70c32f146776a","bc6c07e90a824852871314c2edde98d5","f46b38f981644b4ea29c20c5c6fcf587","9e88b7b2010245a8ad504ae32fd7b059","a373abfce8ff442e9cb379a2623982d6","cc733ecedca749f18ef7a3f9387f7a05","187f57f867764d6790604cf6b2f3b58f","437e2e325d544583815863c57bda5e62","121cf9cbc169466b94490d731dd39dbd","3d133e8bf07641e1aeac089ab2cf4313","fd60ce691e0343ec9ec18d844b22a3f4"]},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1704852902342,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"ed0OpduhX2JF","outputId":"86f1f18e-55f0-4c59-c412-a7d479672a06"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":1,"id":"e1da5fff","metadata":{"executionInfo":{"elapsed":546,"status":"ok","timestamp":1704857114595,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"e1da5fff"},"outputs":[],"source":["# Select CUDA device index\n","import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","model_name_or_path = \"openai/whisper-large-v2\"\n","language = \"Chinese\"\n","language_abbr = \"zh-TW\"\n","task = \"transcribe\"\n","dataset_name = \"mozilla-foundation/common_voice_11_0\""]},{"cell_type":"code","execution_count":null,"id":"Q070AI7XcyZ4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24324,"status":"ok","timestamp":1704852926662,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"Q070AI7XcyZ4","outputId":"3298a9b4-9e2b-483e-fbce-2793cb557357"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"LyM7F9vCPRCH","metadata":{"executionInfo":{"elapsed":16476,"status":"ok","timestamp":1704857135355,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"LyM7F9vCPRCH"},"outputs":[],"source":["# IMPORTS\n","import os\n","import re\n","import subprocess\n","import torch\n","import evaluate\n","import json\n","import pandas as pd\n","import glob\n","\n","# from datasets import load_dataset, DatasetDict\n","# from transformers import WhisperFeatureExtractor\n","# from transformers import WhisperTokenizer\n","# from transformers import WhisperProcessor\n","# from transformers import WhisperForConditionalGeneration\n","# from peft import prepare_model_for_training\n","# from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model, PeftConfig\n","# from transformers import Seq2SeqTrainingArguments\n","# from transformers import Seq2SeqTrainer\n","\n","from datasets import Audio\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n"]},{"cell_type":"markdown","id":"awt7ltO2mnar","metadata":{"id":"awt7ltO2mnar"},"source":["# Convert mp4 into WAV with sample rate 16000"]},{"cell_type":"code","execution_count":3,"id":"rqa9n5uGi9rK","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1704857135355,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"rqa9n5uGi9rK"},"outputs":[],"source":["mp4_folder = '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/data'\n","wav_folder = '/content/drive/MyDrive/WAV_data'\n","cut_wav_folder = '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut'\n","srt_folder = '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/SRT'\n","train_test_split_folder = \"/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/\"\n","train_test_split_data_folder = \"/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data\"\n","testing_folder = os.path.join(train_test_split_data_folder, 'test')\n","training_folder = os.path.join(train_test_split_data_folder, 'train')\n","\n","\n","# assert(os.path.exists(mp4_folder))\n","# assert(os.path.exists(wav_folder))\n","assert(os.path.exists(cut_wav_folder))\n","assert(os.path.exists(srt_folder))\n","assert(os.path.exists(train_test_split_folder))\n","assert(os.path.exists(train_test_split_data_folder))\n","assert(os.path.exists(testing_folder))\n","assert(os.path.exists(training_folder))"]},{"cell_type":"code","execution_count":null,"id":"1TeAzlPlORVM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":840433,"status":"ok","timestamp":1704641173358,"user":{"displayName":"Ian Liu","userId":"10053214275715814514"},"user_tz":300},"id":"1TeAzlPlORVM","outputId":"ff76621f-97d0-42fe-d750-02ae10b8839c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Converted CLC015-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/CLC015-3-字幕版.wav\n","Converted CLC015-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/CLC015-2-字幕版.wav\n","Converted CLC015-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/CLC015-1-字幕版.wav\n","Converted CLC014-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/CLC014-2-字幕版.wav\n","Converted CLC014-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/CLC014-1-字幕版.wav\n","Converted 第13課-4字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第13課-4字幕版.wav\n","Converted 第13課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第13課-1-字幕版.wav\n","Converted 第13課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第13課-3-字幕版.wav\n","Converted 第13課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第13課-2-字幕版.wav\n","Converted 第12课-4-字幕版v1.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第12课-4-字幕版v1.wav\n","Converted 第12课-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第12课-2-字幕版.wav\n","Converted 第12课-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第12课-3-字幕版.wav\n","Converted 第12课-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第12课-1-字幕版.wav\n","Converted 第8課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第8課-3-字幕版.wav\n","Converted 第8課-4-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第8課-4-字幕版.wav\n","Converted 第8課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第8課-1-字幕版.wav\n","Converted 第8課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第8課-2-字幕版.wav\n","Converted 第7課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第7課-1-字幕版.wav\n","Converted 第7課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第7課-3-字幕版.wav\n","Converted 第7課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第7課-2-字幕版.wav\n","Converted 第10課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第10課-2-字幕版.wav\n","Converted 第10課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第10課-1-字幕版.wav\n","Converted 第10課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第10課-3-字幕版.wav\n","Converted 第10課-4-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第10課-4-字幕版.wav\n","Converted 第11課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第11課-3-字幕版.wav\n","Converted 第11課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第11課-1-字幕版.wav\n","Converted 第11課-4-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第11課-4-字幕版.wav\n","Converted 第11課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第11課-2-字幕版.wav\n","Converted 第09課-4-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第09課-4-字幕版.wav\n","Converted 第9課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第9課-2-字幕版.wav\n","Converted 第9課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第9課-1-字幕版.wav\n","Converted 第9課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第9課-3-字幕版.wav\n","Converted 第4課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第4課-2-字幕版.wav\n","Converted 第4課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第4課-1-字幕版.wav\n","Converted 第4課-1-片頭片尾字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第4課-1-片頭片尾字幕版.wav\n","Converted 第6課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第6課-3-字幕版.wav\n","Converted 第6課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第6課-1-字幕版.wav\n","Converted 第6課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第6課-2-字幕版.wav\n","Converted 第2課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第2課-3-字幕版.wav\n","Converted 第2課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第2課-2-字幕版.wav\n","Converted 第2課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第2課-1-字幕版.wav\n","Converted 第2課-3-片頭片尾字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第2課-3-片頭片尾字幕版.wav\n","Converted 第2課-1-片頭片尾字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第2課-1-片頭片尾字幕版.wav\n","Converted 第2課-2-片頭片尾字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第2課-2-片頭片尾字幕版.wav\n","Converted 第3課-2-字幕版 (1).mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第3課-2-字幕版 (1).wav\n","Converted 第3課-1-字幕版 (1).mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第3課-1-字幕版 (1).wav\n","Converted 第3課-3-字幕版 (1).mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第3課-3-字幕版 (1).wav\n","Converted 第5課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第5課-3-字幕版.wav\n","Converted CLC014-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/CLC014-3-字幕版.wav\n","Converted 第5課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第5課-1-字幕版.wav\n","Converted 第5課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第5課-2-字幕版.wav\n","Converted 第3課-3-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第3課-3-字幕版.wav\n","Converted 第3課-2-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第3課-2-字幕版.wav\n","Converted 第3課-1-字幕版.mp4 to /content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_data/第3課-1-字幕版.wav\n"]}],"source":["for mp4_file in os.listdir(mp4_folder):\n","  if mp4_file.endswith('.mp4'):\n","    mp4_path = os.path.join(mp4_folder, mp4_file)\n","\n","    wav_file = os.path.splitext(mp4_file)[0] + '.wav'\n","    wav_path = os.path.join(wav_folder, wav_file)\n","\n","    command = f\"ffmpeg -i '{mp4_path}' '{wav_path}'\"\n","    os.system(command)\n","\n","    print(f\"Converted {mp4_file} to {wav_path}\")\n"]},{"cell_type":"markdown","id":"X5jboyGfYzno","metadata":{"id":"X5jboyGfYzno"},"source":["# Cut and Convert Using ffmpeg"]},{"cell_type":"code","execution_count":4,"id":"9luP-JZ5m_od","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704857135355,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"9luP-JZ5m_od"},"outputs":[],"source":["def replace_spaces(text: str):\n","  return text.replace(\" \", \"\")\n","\n","def remove_punctuation(text: str):\n","  return re.sub(r'[^\\w\\s]','',text)\n","\n","def read_srt(file_path):\n","  with open(file_path, 'r', encoding='utf-8-sig') as file:\n","    lines = file.readlines()\n","\n","  subtitles = []\n","  current_subtitle = None\n","\n","  for line in lines:\n","    if line is None: continue\n","    line = line.strip()\n","\n","    if line.isdigit():\n","      if current_subtitle is not None:\n","          subtitles.append(current_subtitle)\n","      current_subtitle = {\"index\": int(line), \"text\": \"\"}\n","    elif \"-->\" in line:\n","      start, end = line.split(\"-->\")\n","      current_subtitle[\"start\"] = start.strip()\n","      current_subtitle[\"end\"] = end.strip()\n","    elif line is not None and line != \"\":\n","      if current_subtitle is not None:\n","          line = replace_spaces(line)\n","          line = remove_punctuation(line)\n","          current_subtitle[\"text\"] += line + \" \"\n","\n","  if current_subtitle is not None:\n","      subtitles.append(current_subtitle)\n","\n","  return subtitles\n"]},{"cell_type":"code","execution_count":5,"id":"4UAJbOTpKLiB","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704857135355,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"4UAJbOTpKLiB"},"outputs":[],"source":["# Function to convert timestamp to seconds\n","def timestamp_to_seconds(timestamp):\n","    timestamp = timestamp.replace(\",\", \".\")\n","    h, m, s = map(float, timestamp.split(':'))\n","    return h * 3600 + m * 60 + s"]},{"cell_type":"code","execution_count":6,"id":"YfW2iRh0eyDy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1704857135355,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"YfW2iRh0eyDy","outputId":"0ce7aaf8-d2fc-40d1-c6a8-f6458b0a5313"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'dict'>\n","dict_keys(['第10課-2', '第10課-4', '第13課-4', '第11課-4', '第2課-2', '第10課-1', 'CLC014-1', '第12课-4', '第11課-1', '第3課-3', 'CLC015-2', '第13課-1', '第7課-3', '第4課-2', '第2課-1', '第5課-2', '第6課-1', '第8課-1', '第12课-3', '第4課-1', '第2課-3', 'CLC014-2', '第9課-2', 'CLC015-1', '第7課-1', '第8課-4', '第6課-3', '第9課-3', '第8課-2', 'CLC014-3', '第5課-1', '第11課-3', '第3課-1', '第13課-3', '第11課-2', '第3課-2', '第13課-2', '第6課-2', '第12课-1', '第12课-2', '第9課-1', 'CLC015-3', '第7課-2', '第9課-4', '第5課-3', '第8課-3', '第10課-3'])\n","dict_keys(['srt_filepath', 'subtitles', 'audio_filepath', 'audio_files_subtitle_text'])\n","{'srt_filepath': '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/SRT/第10課-2-final.srt', 'subtitles': [{'index': 1, 'text': '大家看那個章天亮教授那個笑談風雲裏面 ', 'start': '00:00:03,545', 'end': '00:00:06,423'}, {'index': 2, 'text': '他前面講了這個三場大風造成改變了中國的歷史 ', 'start': '00:00:06,423', 'end': '00:00:10,510'}, {'index': 3, 'text': '這都是真實的事情 ', 'start': '00:00:10,510', 'end': '00:00:11,970'}, {'index': 4, 'text': '那我再補充一個 ', 'start': '00:00:11,970', 'end': '00:00:13,388'}, {'index': 5, 'text': '當時就是明太祖跟陳友諒大戰的時候 ', 'start': '00:00:13,388', 'end': '00:00:19,769'}, {'index': 6, 'text': '那劉伯溫是明太祖朱元璋的軍師嘛 ', 'start': '00:00:19,769', 'end': '00:00:23,314'}, {'index': 7, 'text': '他們在鄱陽湖大戰的時候呢正打得激烈的時候 ', 'start': '00:00:24,065', 'end': '00:00:27,986'}, {'index': 8, 'text': '是船就是用船打所以他們是坐在船上 ', 'start': '00:00:27,986', 'end': '00:00:30,864'}, {'index': 9, 'text': '劉伯溫呢突然大叫說突然在那兒使勁揮手 ', 'start': '00:00:30,864', 'end': '00:00:34,242'}, {'index': 10, 'text': '朱元璋還以為劉伯溫突然在戰爭中臨場反叛了呢 ', 'start': '00:00:34,242', 'end': '00:00:39,164'}, {'index': 11, 'text': '還嚇了一跳 ', 'start': '00:00:39,164', 'end': '00:00:40,331'}, {'index': 12, 'text': '結果劉伯溫就在那大喊他說難星過急更舟 ', 'start': '00:00:40,582', 'end': '00:00:44,044'}, {'index': 13, 'text': '就是這個難星過甚麼意思呢 ', 'start': '00:00:44,377', 'end': '00:00:47,547'}, {'index': 14, 'text': '他觀測到天上有難星難就有災了 ', 'start': '00:00:47,547', 'end': '00:00:51,009'}, {'index': 15, 'text': '趕快換趕快換船 ', 'start': '00:00:51,009', 'end': '00:00:52,677'}, {'index': 16, 'text': '所以朱元璋就聽他的話了趕快換船 ', 'start': '00:00:52,677', 'end': '00:00:57,140'}, {'index': 17, 'text': '剛換完船然後一個炮那時候是已經發明火藥了有炮 ', 'start': '00:00:57,140', 'end': '00:01:02,145'}, {'index': 18, 'text': '一個炮過來就把原來那個船給炸沉了炸碎了一下就炸碎了 ', 'start': '00:01:02,145', 'end': '00:01:07,067'}, {'index': 19, 'text': '所以這個是當時劉伯溫看到的 ', 'start': '00:01:07,067', 'end': '00:01:10,236'}, {'index': 20, 'text': '中國的歷史上每一朝每一代 ', 'start': '00:01:10,236', 'end': '00:01:12,822'}, {'index': 21, 'text': '這些幫助帝王打天下的都有一些修煉的人 ', 'start': '00:01:12,822', 'end': '00:01:16,201'}, {'index': 22, 'text': '很多是道士也有一些和尚 ', 'start': '00:01:16,201', 'end': '00:01:17,994'}, {'index': 23, 'text': '那麼這些和尚呢 ', 'start': '00:01:17,994', 'end': '00:01:19,120'}, {'index': 24, 'text': '我們從最開始武王伐紂的時候我們就看到了 ', 'start': '00:01:19,120', 'end': '00:01:21,664'}, {'index': 25, 'text': '看這個封神演義裏面那都修道修煉人都出來是不是 ', 'start': '00:01:21,664', 'end': '00:01:25,210'}, {'index': 26, 'text': '所以在人世間來幫這些天子 ', 'start': '00:01:25,210', 'end': '00:01:28,671'}, {'index': 27, 'text': '他們該打天下了該改朝換代了 ', 'start': '00:01:28,671', 'end': '00:01:31,049'}, {'index': 28, 'text': '來幫助人間來做一些事情 ', 'start': '00:01:31,049', 'end': '00:01:33,593'}, {'index': 29, 'text': '所以這個劉伯溫當時其實就是起這個作用 ', 'start': '00:01:33,593', 'end': '00:01:36,137'}, {'index': 30, 'text': '如果是他朱元璋不換的話這個中國的歷史就改了是吧 ', 'start': '00:01:36,137', 'end': '00:01:39,849'}, {'index': 31, 'text': '就不是朱元璋也不是明朝了是吧 ', 'start': '00:01:39,849', 'end': '00:01:42,060'}, {'index': 32, 'text': '所以這種事情在中國的歷史上也是非常多的 ', 'start': '00:01:42,060', 'end': '00:01:45,480'}, {'index': 33, 'text': '我們剛才講這些其實就是說人類的歷史並不是說 ', 'start': '00:01:45,480', 'end': '00:01:51,694'}, {'index': 34, 'text': '我們講哪怕這個唯物歷史觀說是到了甚麼時候叫做時勢造英雄 ', 'start': '00:01:51,694', 'end': '00:01:58,159'}, {'index': 35, 'text': '說到這個時候了該出一個英雄了 ', 'start': '00:01:58,159', 'end': '00:02:00,537'}, {'index': 36, 'text': '然後因為這件事情到這了 ', 'start': '00:02:00,537', 'end': '00:02:02,956'}, {'index': 37, 'text': '所以就有一個英雄他就能夠發揮作用 ', 'start': '00:02:02,956', 'end': '00:02:04,791'}, {'index': 38, 'text': '其實是反過來是反過來的 ', 'start': '00:02:04,791', 'end': '00:02:07,085'}, {'index': 39, 'text': '那個英雄其實他是起的是關鍵作用 ', 'start': '00:02:07,085', 'end': '00:02:10,547'}, {'index': 40, 'text': '而中國人的傳統的歷史觀是說 ', 'start': '00:02:10,547', 'end': '00:02:12,257'}, {'index': 41, 'text': '這個英雄呢是上天派他來的 ', 'start': '00:02:12,257', 'end': '00:02:14,467'}, {'index': 42, 'text': '他該做天子他該建立一個王朝 ', 'start': '00:02:14,592', 'end': '00:02:17,262'}, {'index': 43, 'text': '他該做甚麼事情所以上天派他來 ', 'start': '00:02:17,262', 'end': '00:02:19,514'}, {'index': 44, 'text': '那所有的天象都跟著變 ', 'start': '00:02:19,514', 'end': '00:02:21,224'}, {'index': 45, 'text': '人世間的事人間的事情也跟著安排 ', 'start': '00:02:21,224', 'end': '00:02:25,061'}, {'index': 46, 'text': '也會發生變化都隨著他來 ', 'start': '00:02:25,061', 'end': '00:02:27,313'}, {'index': 47, 'text': '所以正好是相反 ', 'start': '00:02:27,313', 'end': '00:02:28,731'}, {'index': 48, 'text': '但是西方在十八世紀的時候 ', 'start': '00:02:28,731', 'end': '00:02:31,901'}, {'index': 49, 'text': '有一度曾經也流行過這個歷史觀叫做英雄史觀 ', 'start': '00:02:32,902', 'end': '00:02:37,949'}, {'index': 50, 'text': '這個英雄史觀是怎麼說的呢 ', 'start': '00:02:37,949', 'end': '00:02:39,784'}, {'index': 51, 'text': '這個是ThomasCarlyle湯瑪斯卡萊爾 ', 'start': '00:02:39,784', 'end': '00:02:42,787'}, {'index': 52, 'text': '他是ScottishPhilosopherScottishHistorianandPhilosopher ', 'start': '00:02:42,787', 'end': '00:02:48,376'}, {'index': 53, 'text': '他是蘇格蘭的哲學家和歷史學家 ', 'start': '00:02:48,376', 'end': '00:02:52,922'}, {'index': 54, 'text': '那麼他寫了一本書叫 ', 'start': '00:02:52,922', 'end': '00:02:54,090'}, {'index': 55, 'text': 'OnHeroesHeroWorshipandtheHeroicinHistory 關於英雄英雄崇拜和英雄主義 ', 'start': '00:02:54,090', 'end': '00:02:58,052'}, {'index': 56, 'text': 'Heroic就是英雄主義現在叫它英雄主義 ', 'start': '00:02:58,052', 'end': '00:03:02,140'}, {'index': 57, 'text': '他說甚麼呢 ', 'start': '00:03:02,140', 'end': '00:03:03,600'}, {'index': 58, 'text': '他說歷史上的那些事情啊所完成的那些豐功偉績啊 ', 'start': '00:03:04,017', 'end': '00:03:08,730'}, {'index': 59, 'text': '其實都是來自於外部的這個outermaterial ', 'start': '00:03:08,730', 'end': '00:03:14,694'}, {'index': 60, 'text': '來自外部的這些力量在人間實現 ', 'start': '00:03:14,694', 'end': '00:03:19,449'}, {'index': 61, 'text': '在人間怎麼實現呢 ', 'start': '00:03:19,449', 'end': '00:03:21,075'}, {'index': 62, 'text': '那個外部的力量在人間派一個英雄 ', 'start': '00:03:21,075', 'end': '00:03:24,579'}, {'index': 63, 'text': '把那些idea想法告訴那些人就是注到他這個腦子裏 ', 'start': '00:03:24,579', 'end': '00:03:28,541'}, {'index': 64, 'text': '然後在人間實現 ', 'start': '00:03:28,541', 'end': '00:03:30,084'}, {'index': 65, 'text': '其實他的觀點跟中國傳統的觀點是非常接近的 ', 'start': '00:03:30,084', 'end': '00:03:34,797'}, {'index': 66, 'text': '所以他就說我們現在看到的是甚麼 ', 'start': '00:03:34,797', 'end': '00:03:37,550'}, {'index': 67, 'text': '是outermaterialresult ', 'start': '00:03:37,550', 'end': '00:03:39,594'}, {'index': 68, 'text': '是那些外部的力量造成的結果 ', 'start': '00:03:39,594', 'end': '00:03:43,473'}, {'index': 69, 'text': '然後thepracticalrealisationandembodiment ', 'start': '00:03:43,473', 'end': '00:03:47,685'}, {'index': 70, 'text': '我們現在現實中的這些實現啊 ', 'start': '00:03:47,685', 'end': '00:03:51,648'}, {'index': 71, 'text': '從甚麼實現呢 ', 'start': '00:03:51,648', 'end': '00:03:53,024'}, {'index': 72, 'text': 'theThoughtsthatdweltintheGreatMansentintotheworld 被派到人間的偉人驅動他們的思想成就了現實 ', 'start': '00:03:53,024', 'end': '00:03:57,820'}, {'index': 73, 'text': '那些偉人啊他們是sentintotheworld ', 'start': '00:03:57,820', 'end': '00:04:01,449'}, {'index': 74, 'text': '他們是上天派他們來到這個人世間 ', 'start': '00:04:01,449', 'end': '00:04:04,953'}, {'index': 75, 'text': '所以這個史觀在十八世紀的時候 ', 'start': '00:04:04,953', 'end': '00:04:08,831'}, {'index': 76, 'text': '還是跟中國的傳統的史觀是吻合的 ', 'start': '00:04:08,831', 'end': '00:04:11,417'}, {'index': 77, 'text': '但是後來西方和中國的史學家觀點都已經完全不一樣了 ', 'start': '00:04:11,417', 'end': '00:04:16,214'}, {'index': 78, 'text': '現在呢就是純粹從物質的角度來解釋了 ', 'start': '00:04:16,214', 'end': '00:04:19,842'}, {'index': 79, 'text': '那麼我們講了我們前面講過 ', 'start': '00:04:20,260', 'end': '00:04:23,471'}, {'index': 80, 'text': '中國傳統史觀裏邊有一個很重要 ', 'start': '00:04:23,471', 'end': '00:04:26,599'}, {'index': 81, 'text': '一個是它承傳價值我們前面講過了 ', 'start': '00:04:26,599', 'end': '00:04:30,728'}, {'index': 82, 'text': '上明三王之道下辨人事之紀是不是 ', 'start': '00:04:30,728', 'end': '00:04:34,774'}, {'index': 83, 'text': '善善惡惡大家還記得嗎我們前面講過是不是 ', 'start': '00:04:34,774', 'end': '00:04:37,819'}, {'index': 84, 'text': '賢賢賤不肖 ', 'start': '00:04:37,819', 'end': '00:04:39,237'}, {'index': 85, 'text': '所以這個歷史把善的惡的好的壞的都呈現出來 ', 'start': '00:04:39,237', 'end': '00:04:44,867'}, {'index': 86, 'text': '而且有一個評價我們就可以作為參照是吧 ', 'start': '00:04:44,867', 'end': '00:04:47,829'}, {'index': 87, 'text': '還有一個呢叫究天人之際 ', 'start': '00:04:47,829', 'end': '00:04:49,789'}, {'index': 88, 'text': '這是司馬遷寫的究天人之際通古今之變 ', 'start': '00:04:49,789', 'end': '00:04:54,460'}, {'index': 89, 'text': '這是他寫史記的時候 ', 'start': '00:04:54,460', 'end': '00:04:56,337'}, {'index': 90, 'text': '那後世的史觀繼承了這個思想是吧 ', 'start': '00:04:56,337', 'end': '00:04:58,756'}, {'index': 91, 'text': '究天人之際就是要探究天和人之間的關係是吧 ', 'start': '00:04:58,756', 'end': '00:05:04,971'}, {'index': 92, 'text': '那麼從這個歷史中怎麼樣體現出天和人的關係 ', 'start': '00:05:04,971', 'end': '00:05:08,182'}, {'index': 93, 'text': '怎麼樣探究出天和人的關係呢 ', 'start': '00:05:08,182', 'end': '00:05:10,518'}, {'index': 94, 'text': '我們就在講這個概述歷史之前呢 ', 'start': '00:05:10,518', 'end': '00:05:13,688'}, {'index': 95, 'text': '給大家做一個簡要的敘述 ', 'start': '00:05:13,688', 'end': '00:05:16,649'}, {'index': 96, 'text': '我先講一個例子就是這個桑林禱雨 ', 'start': '00:05:16,649', 'end': '00:05:21,154'}, {'index': 97, 'text': '這個是帝鑑圖說裏面的 ', 'start': '00:05:21,154', 'end': '00:05:23,906'}, {'index': 98, 'text': '這件事情是發生在商朝 ', 'start': '00:05:23,906', 'end': '00:05:26,868'}, {'index': 99, 'text': '商朝大家知道開創是商湯 ', 'start': '00:05:26,868', 'end': '00:05:29,454'}, {'index': 100, 'text': '我們平常講這個三王啊其中就有商湯 ', 'start': '00:05:30,330', 'end': '00:05:34,334'}, {'index': 101, 'text': '商湯文王有時候把這個武王也包含在裏面 ', 'start': '00:05:34,334', 'end': '00:05:38,671'}, {'index': 102, 'text': '那麼有時候是把這個大禹放在裏邊 ', 'start': '00:05:38,671', 'end': '00:05:41,549'}, {'index': 103, 'text': '這就是上古的聖王商湯 ', 'start': '00:05:41,549', 'end': '00:05:43,718'}, {'index': 104, 'text': '商湯在位的時候有一次大旱 ', 'start': '00:05:44,093', 'end': '00:05:47,638'}, {'index': 105, 'text': '這個事情是在不同的史書上都有記載 ', 'start': '00:05:47,638', 'end': '00:05:51,017'}, {'index': 106, 'text': '那麼這個帝鑑圖說採用的是淮南子裏面的 ', 'start': '00:05:51,225', 'end': '00:05:55,813'}, {'index': 107, 'text': '我們上回講過淮南子是中國圖書集成 ', 'start': '00:05:55,813', 'end': '00:05:59,942'}, {'index': 108, 'text': '那個淮南王劉安他召集手下的門客 ', 'start': '00:05:59,942', 'end': '00:06:03,613'}, {'index': 109, 'text': '把這八千多部書蒐集起來把它們的內容總和在裏邊的 ', 'start': '00:06:03,613', 'end': '00:06:08,826'}, {'index': 110, 'text': '那這個事情呢在呂氏春秋裏面也有 ', 'start': '00:06:08,826', 'end': '00:06:12,789'}, {'index': 111, 'text': '那麼記載會稍微有一點的差別 ', 'start': '00:06:12,955', 'end': '00:06:15,375'}, {'index': 112, 'text': '那麼在商朝的時候就是商湯繼位以後天下大旱 ', 'start': '00:06:15,375', 'end': '00:06:21,881'}, {'index': 113, 'text': '那我們講了這個天下大旱像這種 ', 'start': '00:06:22,340', 'end': '00:06:24,675'}, {'index': 114, 'text': '這是上天降下來的一個信號 ', 'start': '00:06:24,675', 'end': '00:06:28,388'}, {'index': 115, 'text': '這叫災或者是祥 ', 'start': '00:06:28,388', 'end': '00:06:32,475'}, {'index': 116, 'text': '這個祥就是祥瑞的祥 ', 'start': '00:06:32,475', 'end': '00:06:35,603'}, {'index': 117, 'text': '所以這個災或者是祥或者是祥瑞或者是災異 ', 'start': '00:06:35,603', 'end': '00:06:40,441'}, {'index': 118, 'text': '這都叫祥詳那就是上天降下來的異象是天象 ', 'start': '00:06:40,441', 'end': '00:06:44,654'}, {'index': 119, 'text': '那麼怎麼辦呢 ', 'start': '00:06:44,654', 'end': '00:06:45,905'}, {'index': 120, 'text': '商湯就說我要為萬民祈禱向上天求雨 ', 'start': '00:06:45,905', 'end': '00:06:51,077'}, {'index': 121, 'text': '他就要登上祭壇上去求雨 ', 'start': '00:06:51,077', 'end': '00:06:53,913'}, {'index': 122, 'text': '那麼他去求雨的時候開始占卜的人說 ', 'start': '00:06:53,913', 'end': '00:06:58,084'}, {'index': 123, 'text': '你啊應該要犧牲 ', 'start': '00:06:58,084', 'end': '00:07:00,128'}, {'index': 124, 'text': '這個犧牲這個詞 ', 'start': '00:07:00,128', 'end': '00:07:01,254'}, {'index': 125, 'text': '我們現在說犧牲是共產黨說那個甚麼烈士犧牲 ', 'start': '00:07:01,254', 'end': '00:07:04,799'}, {'index': 126, 'text': '以前這個犧牲是祭祀的時候 ', 'start': '00:07:04,799', 'end': '00:07:07,677'}, {'index': 127, 'text': '把豬啊或牛啊獻給上天或者祖宗那個叫犧牲 ', 'start': '00:07:07,677', 'end': '00:07:13,266'}, {'index': 128, 'text': '所以祭祀的這個動物這個動物叫犧牲 ', 'start': '00:07:13,266', 'end': '00:07:17,520'}, {'index': 129, 'text': '那麼他就說呢需要一個人來犧牲 ', 'start': '00:07:17,520', 'end': '00:07:20,022'}, {'index': 130, 'text': '一個人來作為犧牲給這個上天祭祀才能夠祭祀成功 ', 'start': '00:07:20,022', 'end': '00:07:24,652'}, {'index': 131, 'text': '因為七年大旱啊其實不是說這一次才禱雨 ', 'start': '00:07:24,652', 'end': '00:07:29,157'}, {'index': 132, 'text': '前面都祈禱過很多次都不行嘛 ', 'start': '00:07:29,157', 'end': '00:07:31,784'}, {'index': 133, 'text': '所以這個占卜呢就說你要誠心 ', 'start': '00:07:31,784', 'end': '00:07:33,744'}, {'index': 134, 'text': '而且要以人來祭祀才行 ', 'start': '00:07:33,744', 'end': '00:07:35,621'}, {'index': 135, 'text': '那後來這個商湯就說以人祭祀我本來就是為萬民祈禱是吧 ', 'start': '00:07:35,621', 'end': '00:07:40,376'}, {'index': 136, 'text': '要以人祭祀呢這個我於心不忍 ', 'start': '00:07:40,376', 'end': '00:07:43,629'}, {'index': 137, 'text': '但是上天如果說確實是需要人來祭祀呢 ', 'start': '00:07:43,629', 'end': '00:07:46,757'}, {'index': 138, 'text': '那我也是人嘛就拿我來吧 ', 'start': '00:07:46,757', 'end': '00:07:48,718'}, {'index': 139, 'text': '就說讓我來做這個犧牲 ', 'start': '00:07:48,718', 'end': '00:07:49,927'}, {'index': 140, 'text': '所以他就自己齋戒然後沐浴 ', 'start': '00:07:49,927', 'end': '00:07:54,599'}, {'index': 141, 'text': '然後換上恭恭敬敬的這個叫做身纏白茅那個白色的茅草 ', 'start': '00:07:54,599', 'end': '00:08:00,938'}, {'index': 142, 'text': '然後就指甲剪掉頭髮弄掉然後恭恭敬敬到這個祭壇上 ', 'start': '00:08:00,938', 'end': '00:08:06,736'}, {'index': 143, 'text': '就以七六件事情來自責 ', 'start': '00:08:06,986', 'end': '00:08:10,281'}, {'index': 144, 'text': '說上天不下雨啊如果是因為有甚麼原因呢 ', 'start': '00:08:10,281', 'end': '00:08:14,869'}, {'index': 145, 'text': '歸罪都在我身上不要歸罪萬民不要歸罪其他的人 ', 'start': '00:08:15,203', 'end': '00:08:22,293'}, {'index': 146, 'text': '有罪的是我因為我是上天派下來的天子是吧 ', 'start': '00:08:22,293', 'end': '00:08:25,671'}, {'index': 147, 'text': '所以我有責任 ', 'start': '00:08:25,671', 'end': '00:08:26,881'}, {'index': 148, 'text': '那麼我呢是不是以下七六件事情沒有做好 ', 'start': '00:08:26,881', 'end': '00:08:31,427'}, {'index': 149, 'text': '所以他就列六件事情沒有做好 ', 'start': '00:08:31,427', 'end': '00:08:34,096'}, {'index': 150, 'text': '所以他說呢 ', 'start': '00:08:34,096', 'end': '00:08:35,056'}, {'index': 151, 'text': '第一個呢是不是我的政事 ', 'start': '00:08:35,056', 'end': '00:08:37,683'}, {'index': 152, 'text': '我這個安排啊朝政安排的不合適 ', 'start': '00:08:38,518', 'end': '00:08:42,438'}, {'index': 153, 'text': '是不是或者是百姓流離失所 ', 'start': '00:08:42,647', 'end': '00:08:46,317'}, {'index': 154, 'text': '是不是宮室我營建的宮室太過繁華了 ', 'start': '00:08:46,317', 'end': '00:08:51,948'}, {'index': 155, 'text': '或者是不是這個後宮啊 ', 'start': '00:08:51,948', 'end': '00:08:55,284'}, {'index': 156, 'text': '後宮裏邊這些女人刮枕邊風 ', 'start': '00:08:55,284', 'end': '00:08:59,830'}, {'index': 157, 'text': '就是說這個干涉朝政就像妲己一樣是不是有這樣的事情 ', 'start': '00:08:59,830', 'end': '00:09:03,501'}, {'index': 158, 'text': '或者呢是不是有這個小人進讒言 ', 'start': '00:09:03,501', 'end': '00:09:06,837'}, {'index': 159, 'text': '說完了以後呢他就準備要去點火了 ', 'start': '00:09:07,380', 'end': '00:09:11,300'}, {'index': 160, 'text': '就在這個時候突然一場大雨下來 ', 'start': '00:09:11,300', 'end': '00:09:13,553'}, {'index': 161, 'text': '然後方圓幾千里地都是大雨 ', 'start': '00:09:13,553', 'end': '00:09:17,640'}, {'index': 162, 'text': '一下就把這個旱災就解了 ', 'start': '00:09:17,640', 'end': '00:09:19,600'}, {'index': 163, 'text': '這個是記載在史書上 ', 'start': '00:09:19,600', 'end': '00:09:21,519'}, {'index': 164, 'text': '我們剛才講了在淮南子和在呂氏春秋裏邊都有 ', 'start': '00:09:21,519', 'end': '00:09:25,731'}, {'index': 165, 'text': '但是這兩個裏面說的不一樣 ', 'start': '00:09:25,731', 'end': '00:09:27,733'}, {'index': 166, 'text': '呂氏春秋裏面是說七年大旱 ', 'start': '00:09:27,733', 'end': '00:09:30,444'}, {'index': 167, 'text': '淮南子呢是說五年大旱 ', 'start': '00:09:30,444', 'end': '00:09:32,697'}, {'index': 168, 'text': '但這個不是大的問題 ', 'start': '00:09:32,697', 'end': '00:09:34,782'}, {'index': 169, 'text': '就是說確實有這麼一件事情 ', 'start': '00:09:34,782', 'end': '00:09:36,826'}, {'index': 170, 'text': '那後來呢因為這場大雨 ', 'start': '00:09:37,577', 'end': '00:09:39,704'}, {'index': 171, 'text': '這個老百姓就感恩嘛 ', 'start': '00:09:39,704', 'end': '00:09:41,872'}, {'index': 172, 'text': '所以後來商朝就傳下來一首樂舞 ', 'start': '00:09:41,872', 'end': '00:09:45,543'}, {'index': 173, 'text': '這個樂舞呢就叫桑林之舞 ', 'start': '00:09:45,543', 'end': '00:09:47,795'}, {'index': 174, 'text': '就是這個桑林他們祭祀的這個地方叫桑林這是地名 ', 'start': '00:09:47,795', 'end': '00:09:52,049'}, {'index': 175, 'text': '後來傳下來這個樂舞就叫桑林之舞 ', 'start': '00:09:52,133', 'end': '00:09:54,427'}, {'index': 176, 'text': '這個桑林之舞是上古三代的時候傳下來的非常有名的 ', 'start': '00:09:54,427', 'end': '00:09:58,556'}, {'index': 177, 'text': '那後來這個傳統 ', 'start': '00:09:58,556', 'end': '00:10:00,891'}, {'index': 178, 'text': '就是這個桑林之舞這樣的樂舞它幹甚麼呢 ', 'start': '00:10:00,891', 'end': '00:10:04,312'}, {'index': 179, 'text': '做兩件事情一個是感恩上天一個是歌頌商湯的功德 ', 'start': '00:10:04,437', 'end': '00:10:11,152'}, {'index': 180, 'text': '所以我們後來就有一個成語叫做歌功頌德 ', 'start': '00:10:11,152', 'end': '00:10:15,489'}, {'index': 181, 'text': '歌功頌德是這個意思 ', 'start': '00:10:15,489', 'end': '00:10:17,366'}, {'index': 182, 'text': '現在說歌功頌德是反的 ', 'start': '00:10:17,366', 'end': '00:10:19,493'}, {'index': 183, 'text': '以前的歌功頌德是這個意思 ', 'start': '00:10:19,493', 'end': '00:10:21,412'}, {'index': 184, 'text': '是他的德行他的功績然後呢感恩上天 ', 'start': '00:10:21,412', 'end': '00:10:25,458'}, {'index': 185, 'text': '所以為甚麼要傳這個 ', 'start': '00:10:25,458', 'end': '00:10:26,917'}, {'index': 186, 'text': '這個中國禮樂文化禮樂文明 ', 'start': '00:10:26,917', 'end': '00:10:30,630'}, {'index': 187, 'text': '這個樂和舞是連在一起的這是禮樂文明 ', 'start': '00:10:30,630', 'end': '00:10:34,008'}, {'index': 188, 'text': '這個是在我們禮樂文化裏面很重要的桑林之舞 ', 'start': '00:10:34,008', 'end': '00:10:38,137'}, {'index': 189, 'text': '好我給大家過一下這個解釋一下 ', 'start': '00:10:38,137', 'end': '00:10:42,391'}, {'index': 190, 'text': '這個應該不難 ', 'start': '00:10:42,391', 'end': '00:10:44,560'}, {'index': 191, 'text': '那他說這個 ', 'start': '00:10:45,186', 'end': '00:10:46,687'}, {'index': 192, 'text': '這是上回我們講的這個帝鑑圖說 ', 'start': '00:10:46,687', 'end': '00:10:48,981'}, {'index': 193, 'text': '他說商史紀成湯時成湯就是商湯 ', 'start': '00:10:48,981', 'end': '00:10:53,361'}, {'index': 194, 'text': '歲久大旱太史占之曰 ', 'start': '00:10:54,737', 'end': '00:10:58,282'}, {'index': 195, 'text': '太史就是太史我們上回講過他又是史官又是天文官 ', 'start': '00:10:58,282', 'end': '00:11:03,412'}, {'index': 196, 'text': '所以這個太史他占卜說應該以人禱 ', 'start': '00:11:03,412', 'end': '00:11:06,916'}, {'index': 197, 'text': '禱是祈禱或者祭祀那麼應該用人來祈禱 ', 'start': '00:11:06,916', 'end': '00:11:10,586'}, {'index': 198, 'text': '那商湯就說吾所以請雨者人也 ', 'start': '00:11:10,586', 'end': '00:11:13,714'}, {'index': 199, 'text': '我是為人來求雨的 ', 'start': '00:11:13,714', 'end': '00:11:16,300'}, {'index': 200, 'text': '若必以人如果必須要用人來作為犧牲呢 ', 'start': '00:11:16,300', 'end': '00:11:19,345'}, {'index': 201, 'text': '那吾請自當我就自己來吧用我自己 ', 'start': '00:11:19,345', 'end': '00:11:24,058'}, {'index': 202, 'text': '遂齋戒剪髮斷爪 ', 'start': '00:11:24,058', 'end': '00:11:27,269'}, {'index': 203, 'text': '這個爪的意思就是那個指甲 ', 'start': '00:11:27,269', 'end': '00:11:29,397'}, {'index': 204, 'text': '不是那個爪 ', 'start': '00:11:29,397', 'end': '00:11:30,398'}, {'index': 205, 'text': '我們說那個爪那是動物以前說這個爪是指甲 ', 'start': '00:11:31,774', 'end': '00:11:35,403'}, {'index': 206, 'text': '素車白馬 ', 'start': '00:11:35,403', 'end': '00:11:36,529'}, {'index': 207, 'text': '這是你要祭祀嘛 ', 'start': '00:11:36,529', 'end': '00:11:37,571'}, {'index': 208, 'text': '所以素車就是不能有任何裝飾的車和白馬 ', 'start': '00:11:37,571', 'end': '00:11:41,909'}, {'index': 209, 'text': '身嬰白茅身上纏上身嬰白茅就是身上纏那個白色的茅草 ', 'start': '00:11:41,909', 'end': '00:11:46,914'}, {'index': 210, 'text': '以為犧牲我們剛剛才講這個犧牲 ', 'start': '00:11:46,914', 'end': '00:11:49,125'}, {'index': 211, 'text': '禱於桑林之野 ', 'start': '00:11:49,125', 'end': '00:11:50,918'}, {'index': 212, 'text': '那麼以六件事情來問責自己 ', 'start': '00:11:51,752', 'end': '00:11:54,839'}, {'index': 213, 'text': '是問上蒼實際上是跟上蒼 ', 'start': '00:11:54,839', 'end': '00:11:57,133'}, {'index': 214, 'text': '說是不是我以下這些事情做的不對 ', 'start': '00:11:57,133', 'end': '00:11:59,760'}, {'index': 215, 'text': '第一件事政不節歟 ', 'start': '00:11:59,760', 'end': '00:12:01,929'}, {'index': 216, 'text': '這個歟是語氣詞就是相當於嗎 ', 'start': '00:12:01,929', 'end': '00:12:04,974'}, {'index': 217, 'text': '那我的政事做的不好不夠節制 ', 'start': '00:12:04,974', 'end': '00:12:09,353'}, {'index': 218, 'text': '民失職歟是不是老百姓啊他們 ', 'start': '00:12:09,770', 'end': '00:12:13,232'}, {'index': 219, 'text': '失職就是老百姓他們不能夠安居樂業 ', 'start': '00:12:13,232', 'end': '00:12:17,445'}, {'index': 220, 'text': '我們現在話講就是不能夠安居樂業 ', 'start': '00:12:17,445', 'end': '00:12:20,114'}, {'index': 221, 'text': '那就是老百姓流離失所嘛 ', 'start': '00:12:20,114', 'end': '00:12:21,907'}, {'index': 222, 'text': '然後第三個他說宮室崇歟 ', 'start': '00:12:21,907', 'end': '00:12:25,202'}, {'index': 223, 'text': '崇就是奢華高大是吧 ', 'start': '00:12:25,202', 'end': '00:12:28,873'}, {'index': 224, 'text': '營建宮室 ', 'start': '00:12:28,873', 'end': '00:12:30,040'}, {'index': 225, 'text': '大家知道那個商紂王 ', 'start': '00:12:30,040', 'end': '00:12:31,167'}, {'index': 226, 'text': '他就是營建那個高臺啊營建富麗堂皇的宮殿啊 ', 'start': '00:12:31,167', 'end': '00:12:36,338'}, {'index': 227, 'text': '凡是這些亡國之君一般都喜歡幹這些事情 ', 'start': '00:12:36,338', 'end': '00:12:40,509'}, {'index': 228, 'text': '所以他說是不是因為這個呢 ', 'start': '00:12:40,509', 'end': '00:12:42,178'}, {'index': 229, 'text': '或者是女謁盛歟這個謁的意思是覲見 ', 'start': '00:12:42,178', 'end': '00:12:47,141'}, {'index': 230, 'text': '就是說你要覲見一個皇上下級要見上級這叫謁 ', 'start': '00:12:47,141', 'end': '00:12:53,314'}, {'index': 231, 'text': '那麼你要去覲見皇上那有一個人要引薦你啊 ', 'start': '00:12:53,314', 'end': '00:12:56,192'}, {'index': 232, 'text': '那個引薦的人帶你的那個人 ', 'start': '00:12:56,192', 'end': '00:12:58,778'}, {'index': 233, 'text': '那個導引你的那個人那叫謁者 ', 'start': '00:12:58,778', 'end': '00:13:01,447'}, {'index': 234, 'text': '那這個女謁的意思是甚麼呢 ', 'start': '00:13:01,447', 'end': '00:13:03,240'}, {'index': 235, 'text': '女謁盛歟呢是我想要做一件甚麼事情 ', 'start': '00:13:03,240', 'end': '00:13:06,827'}, {'index': 236, 'text': '我想跟皇帝說一件事情或者是想覲見 ', 'start': '00:13:06,827', 'end': '00:13:09,205'}, {'index': 237, 'text': '一個壞人想進讒言跟皇帝進讒言 ', 'start': '00:13:09,205', 'end': '00:13:11,248'}, {'index': 238, 'text': '你不能夠想見皇帝就見到了對不對 ', 'start': '00:13:11,248', 'end': '00:13:14,376'}, {'index': 239, 'text': '所以這種人他可能就會去找那個後宮找那個嬪妃 ', 'start': '00:13:14,376', 'end': '00:13:18,297'}, {'index': 240, 'text': '讓她們來跟皇帝來說這種情況就叫女謁 ', 'start': '00:13:18,297', 'end': '00:13:21,884'}, {'index': 241, 'text': '就是嬪妃她們在這個皇帝面前進讒言做不好 ', 'start': '00:13:21,884', 'end': '00:13:29,058'}, {'index': 242, 'text': '所以這種情況是屬於就跟妲己禍亂朝廷一樣 ', 'start': '00:13:29,058', 'end': '00:13:33,604'}, {'index': 243, 'text': '妲己不是就幹壞事嗎 ', 'start': '00:13:33,604', 'end': '00:13:35,022'}, {'index': 244, 'text': '所以這種情況就屬於是陰陽反背 ', 'start': '00:13:35,022', 'end': '00:13:37,983'}, {'index': 245, 'text': '這個在傳統的禮法中女人是不能干政的 ', 'start': '00:13:37,983', 'end': '00:13:44,782'}, {'index': 246, 'text': '所以呢它是就是跟妲己一樣這個也是亡國之兆是吧 ', 'start': '00:13:44,782', 'end': '00:13:48,118'}, {'index': 247, 'text': '女謁盛歟這個盛是這種情況很多盛就是很興盛嘛 ', 'start': '00:13:48,118', 'end': '00:13:53,749'}, {'index': 248, 'text': '包苴行歟這個包苴是賄賂的意思 ', 'start': '00:13:54,416', 'end': '00:13:58,254'}, {'index': 249, 'text': '就是我們現在行賄受賄這個古代叫包苴 ', 'start': '00:13:58,254', 'end': '00:14:01,549'}, {'index': 250, 'text': '為甚麼叫包苴呢 ', 'start': '00:14:01,549', 'end': '00:14:02,925'}, {'index': 251, 'text': '這個苴是一種草是一種茅草 ', 'start': '00:14:02,925', 'end': '00:14:05,636'}, {'index': 252, 'text': '包苴呢就是我要送你一個禮物啊 ', 'start': '00:14:06,220', 'end': '00:14:09,849'}, {'index': 253, 'text': '那我一般來說就是 ', 'start': '00:14:10,391', 'end': '00:14:12,685'}, {'index': 254, 'text': '你看大家是現在你買一個禮物 ', 'start': '00:14:12,685', 'end': '00:14:14,395'}, {'index': 255, 'text': '它還有個Wrap包裝很漂亮 ', 'start': '00:14:14,395', 'end': '00:14:15,855'}, {'index': 256, 'text': '給你一個包裝把那個禮物包起來 ', 'start': '00:14:15,855', 'end': '00:14:18,065'}, {'index': 257, 'text': '人家一看這是一個很好的東西是吧 ', 'start': '00:14:18,065', 'end': '00:14:20,860'}, {'index': 258, 'text': '古代是反過來的是因為表示謙虛 ', 'start': '00:14:20,860', 'end': '00:14:23,279'}, {'index': 259, 'text': '我送你一個東西然後我就說哎呀這個沒甚麼東西 ', 'start': '00:14:23,279', 'end': '00:14:26,240'}, {'index': 260, 'text': '這個一點小意思笑納吧 ', 'start': '00:14:26,240', 'end': '00:14:28,200'}, {'index': 261, 'text': '所以他就送你哪怕是好東西我也說這個是不好對不對 ', 'start': '00:14:28,200', 'end': '00:14:31,954'}, {'index': 262, 'text': '所以一般來說它不會有這種包 ', 'start': '00:14:31,954', 'end': '00:14:33,956'}, {'index': 263, 'text': '但是也有一種情況要把它包起來 ', 'start': '00:14:33,956', 'end': '00:14:35,749'}, {'index': 264, 'text': '甚麼樣情況包起來呢 ', 'start': '00:14:35,749', 'end': '00:14:37,126'}, {'index': 265, 'text': '你要行賄的時候你把它包起來 ', 'start': '00:14:37,126', 'end': '00:14:39,086'}, {'index': 266, 'text': '因為你不想讓別人知道你在行賄嘛 ', 'start': '00:14:39,086', 'end': '00:14:41,630'}, {'index': 267, 'text': '所以你行賄的時候呢拿茅草把它包起來 ', 'start': '00:14:41,630', 'end': '00:14:44,300'}, {'index': 268, 'text': '那茅草人家說你還送了一個茅草是吧 ', 'start': '00:14:44,300', 'end': '00:14:46,594'}, {'index': 269, 'text': '這個其實沒甚麼東西裏面可能是金銀財寶是吧 ', 'start': '00:14:46,594', 'end': '00:14:49,513'}, {'index': 270, 'text': '所以這個後來就演變成這個詞 ', 'start': '00:14:49,513', 'end': '00:14:52,391'}, {'index': 271, 'text': '就包苴的意思就是說是行賄 ', 'start': '00:14:52,391', 'end': '00:14:54,435'}, {'index': 272, 'text': '所以讒夫 ', 'start': '00:14:54,435', 'end': '00:14:56,395'}, {'index': 273, 'text': '讒夫就是進讒言的這種人 ', 'start': '00:14:56,395', 'end': '00:14:58,647'}, {'index': 274, 'text': '昌很昌盛是吧昌歟 ', 'start': '00:14:58,647', 'end': '00:15:00,816'}, {'index': 275, 'text': '說還沒說完呢大雨方數千里 ', 'start': '00:15:00,816', 'end': '00:15:03,360'}, {'index': 276, 'text': '方是方圓方圓數千里 ', 'start': '00:15:03,360', 'end': '00:15:05,321'}, {'index': 277, 'text': '這個張居正給小皇帝後面的解啊 ', 'start': '00:15:05,613', 'end': '00:15:08,824'}, {'index': 278, 'text': '這個它是說解釋是說甚麼 ', 'start': '00:15:08,824', 'end': '00:15:10,868'}, {'index': 279, 'text': '商史上記 ', 'start': '00:15:10,868', 'end': '00:15:11,869'}, {'index': 280, 'text': '這個就比較容易理解了 ', 'start': '00:15:11,869', 'end': '00:15:13,495'}, {'index': 281, 'text': '成湯之時歲久不雨天下大旱 ', 'start': '00:15:13,495', 'end': '00:15:16,123'}, {'index': 282, 'text': '靈臺靈臺官 ', 'start': '00:15:16,332', 'end': '00:15:18,000'}, {'index': 283, 'text': '靈臺官就是這個天文官 ', 'start': '00:15:18,000', 'end': '00:15:20,753'}, {'index': 284, 'text': '觀天象的這個臺啊這個天文臺叫做靈臺 ', 'start': '00:15:20,753', 'end': '00:15:24,131'}, {'index': 285, 'text': '所以這個靈臺官的意思就是這個天文官 ', 'start': '00:15:24,214', 'end': '00:15:28,135'}, {'index': 286, 'text': '天文官這個太史太史占候 ', 'start': '00:15:28,302', 'end': '00:15:31,305'}, {'index': 287, 'text': '這個靈臺在這個古書上裏面記載 ', 'start': '00:15:32,181', 'end': '00:15:36,143'}, {'index': 288, 'text': '就是我們現在看的 ', 'start': '00:15:36,143', 'end': '00:15:39,063'}, {'index': 289, 'text': '就是如果你要看這個封神演義裏面就有 ', 'start': '00:15:39,063', 'end': '00:15:42,274'}, {'index': 290, 'text': '這個老百姓幫著周文王修建那個靈臺 ', 'start': '00:15:42,274', 'end': '00:15:46,236'}, {'index': 291, 'text': '因為周文王說我要觀天象是吧要修建靈臺 ', 'start': '00:15:46,236', 'end': '00:15:49,281'}, {'index': 292, 'text': '然後這個老百姓一聽踴躍幫忙 ', 'start': '00:15:49,281', 'end': '00:15:51,533'}, {'index': 293, 'text': '所以就開始挖土啊幹嘛去修這個靈臺很快就成了 ', 'start': '00:15:51,533', 'end': '00:15:54,912'}, {'index': 294, 'text': '結果還出現一件事情 ', 'start': '00:15:54,912', 'end': '00:15:56,330'}, {'index': 295, 'text': '挖挖挖突然挖出來三具幾具枯骨 ', 'start': '00:15:56,330', 'end': '00:15:59,959'}, {'index': 296, 'text': '這死人的枯骨 ', 'start': '00:16:00,250', 'end': '00:16:01,460'}, {'index': 297, 'text': '然後那些人就說這個荒郊野外不知道是誰的 ', 'start': '00:16:01,460', 'end': '00:16:05,464'}, {'index': 298, 'text': '這些枯骨就這樣扔了吧 ', 'start': '00:16:05,464', 'end': '00:16:07,591'}, {'index': 299, 'text': '當時那個周文王說 ', 'start': '00:16:07,925', 'end': '00:16:09,677'}, {'index': 300, 'text': '這個枯骨咱們要把它好好的厚葬 ', 'start': '00:16:09,677', 'end': '00:16:12,596'}, {'index': 301, 'text': '好好的埋葬起來恭恭敬敬埋葬起來 ', 'start': '00:16:12,596', 'end': '00:16:16,058'}, {'index': 302, 'text': '那底下的人說這個又不知道它是誰的枯骨是吧 ', 'start': '00:16:16,058', 'end': '00:16:18,894'}, {'index': 303, 'text': '那周文王就說 ', 'start': '00:16:19,144', 'end': '00:16:20,771'}, {'index': 304, 'text': '這個枯骨在我的地盤上那就是我的子民 ', 'start': '00:16:20,771', 'end': '00:16:24,692'}, {'index': 305, 'text': '所以他們沒有能夠得到很好的安葬是我的責任 ', 'start': '00:16:24,692', 'end': '00:16:28,320'}, {'index': 306, 'text': '就應該把他們 ', 'start': '00:16:28,320', 'end': '00:16:29,238'}, {'index': 307, 'text': '我應該盡我的責任給他們很好的安葬 ', 'start': '00:16:29,238', 'end': '00:16:31,782'}, {'index': 308, 'text': '所以後來這個老百姓就傳頌說這個周文王啊澤及枯骨 ', 'start': '00:16:31,782', 'end': '00:16:35,285'}, {'index': 309, 'text': '他的那個恩惠啊 ', 'start': '00:16:35,285', 'end': '00:16:37,037'}, {'index': 310, 'text': '連這個枯骨都能夠受到恩惠是吧 ', 'start': '00:16:37,037', 'end': '00:16:39,456'}, {'index': 311, 'text': '所以這個天下就歸順了周文王 ', 'start': '00:16:39,456', 'end': '00:16:41,875'}, {'index': 312, 'text': '當然那個時候就是靈臺 ', 'start': '00:16:41,875', 'end': '00:16:43,711'}, {'index': 313, 'text': '你要如果看那個西遊記裏面它也說這個靈臺 ', 'start': '00:16:43,711', 'end': '00:16:48,298'}, {'index': 314, 'text': '大家有記得西遊記裏面說靈臺嗎 ', 'start': '00:16:48,298', 'end': '00:16:50,300'}, {'index': 315, 'text': '這個裏面 ', 'start': '00:16:53,220', 'end': '00:16:54,304'}, {'index': 316, 'text': '那個孫悟空去拜師父的時候 ', 'start': '00:16:54,930', 'end': '00:16:57,808'}, {'index': 317, 'text': '拜那個菩提老祖的時候 ', 'start': '00:16:57,808', 'end': '00:16:59,143'}, {'index': 318, 'text': '去的那個地方那個山叫靈臺山 ', 'start': '00:16:59,143', 'end': '00:17:01,979'}, {'index': 319, 'text': '斜月三星洞 ', 'start': '00:17:01,979', 'end': '00:17:03,605'}, {'index': 320, 'text': '那個靈臺 ', 'start': '00:17:03,605', 'end': '00:17:04,732'}, {'index': 321, 'text': '斜月三星洞大家知道吧 ', 'start': '00:17:04,732', 'end': '00:17:06,483'}, {'index': 322, 'text': '是個心字靈臺呢同時又也可以指心 ', 'start': '00:17:06,483', 'end': '00:17:10,696'}, {'index': 323, 'text': '在中國這個傳統裏面這個靈臺也可以表示心 ', 'start': '00:17:10,696', 'end': '00:17:14,033'}, {'index': 324, 'text': '所以這個靈臺官占候 ', 'start': '00:17:14,033', 'end': '00:17:16,827'}, {'index': 325, 'text': '這個候就是天象 ', 'start': '00:17:16,827', 'end': '00:17:18,495'}, {'index': 326, 'text': '這個候候甚麼候天象 ', 'start': '00:17:18,495', 'end': '00:17:20,831'}, {'index': 327, 'text': '說呢這旱災須是殺個人祈禱乃得雨 ', 'start': '00:17:20,831', 'end': '00:17:25,836'}, {'index': 328, 'text': '他才能夠求到雨 ', 'start': '00:17:25,836', 'end': '00:17:27,671'}, {'index': 329, 'text': '成湯就說我所以求雨呢就是要救濟活人 ', 'start': '00:17:27,671', 'end': '00:17:31,300'}, {'index': 330, 'text': '生人是活人 ', 'start': '00:17:31,300', 'end': '00:17:32,342'}, {'index': 331, 'text': '又豈忍殺人以為禱乎 ', 'start': '00:17:32,342', 'end': '00:17:34,344'}, {'index': 332, 'text': '如果必須要用人來 ', 'start': '00:17:34,344', 'end': '00:17:36,055'}, {'index': 333, 'text': '那寧可我自己來吧 ', 'start': '00:17:36,055', 'end': '00:17:37,765'}, {'index': 334, 'text': '當就是抵當就是比如我們到當鋪是吧 ', 'start': '00:17:37,765', 'end': '00:17:40,809'}, {'index': 335, 'text': '大家知道那個當鋪吧聽說過吧 ', 'start': '00:17:40,809', 'end': '00:17:42,811'}, {'index': 336, 'text': '就是你缺錢了你得拿個東西拿戒指去換一些錢嘛 ', 'start': '00:17:42,811', 'end': '00:17:46,940'}, {'index': 337, 'text': '就是典當嘛所以這個當呢就是換的意思 ', 'start': '00:17:46,940', 'end': '00:17:49,943'}, {'index': 338, 'text': '就拿我來換祈禱這個人 ', 'start': '00:17:49,943', 'end': '00:17:53,238'}, {'index': 339, 'text': '當是這個意思 ', 'start': '00:17:53,238', 'end': '00:17:54,698'}, {'index': 340, 'text': '然後遂齋戒身心剪斷爪髮 ', 'start': '00:17:54,698', 'end': '00:17:58,243'}, {'index': 341, 'text': '素車白馬減損服禦 ', 'start': '00:17:58,243', 'end': '00:18:00,537'}, {'index': 342, 'text': '這個因為皇帝出車它是有禮嘛 ', 'start': '00:18:00,537', 'end': '00:18:03,207'}, {'index': 343, 'text': '減損就是不要穿啊這些包括裝飾啊 ', 'start': '00:18:03,207', 'end': '00:18:07,544'}, {'index': 344, 'text': '都要減損 ', 'start': '00:18:07,544', 'end': '00:18:08,545'}, {'index': 345, 'text': '身上披著白茅草 ', 'start': '00:18:08,545', 'end': '00:18:10,339'}, {'index': 346, 'text': '就如祭祀的犧牲模樣 ', 'start': '00:18:10,339', 'end': '00:18:12,758'}, {'index': 347, 'text': '我剛才講的這個犧牲 ', 'start': '00:18:12,758', 'end': '00:18:14,301'}, {'index': 348, 'text': '乃出禱於桑林之野 ', 'start': '00:18:14,301', 'end': '00:18:17,304'}, {'index': 349, 'text': '這個桑林之野 ', 'start': '00:18:17,304', 'end': '00:18:18,722'}, {'index': 350, 'text': '這個我們講這個野是甚麼意思呢 ', 'start': '00:18:18,722', 'end': '00:18:21,225'}, {'index': 351, 'text': '不是野外 ', 'start': '00:18:21,558', 'end': '00:18:22,893'}, {'index': 352, 'text': '古代的時候呢那個城啊我們現在叫城 ', 'start': '00:18:23,769', 'end': '00:18:27,898'}, {'index': 353, 'text': '還有一個詞叫做城郭大家知道吧 ', 'start': '00:18:27,898', 'end': '00:18:30,234'}, {'index': 354, 'text': '這個城郭是兩道城牆 ', 'start': '00:18:30,400', 'end': '00:18:33,278'}, {'index': 355, 'text': '裏邊的那個叫城外邊的這一道叫做郭 ', 'start': '00:18:33,278', 'end': '00:18:37,241'}, {'index': 356, 'text': '裏邊的皇帝居住的那個城啊那個是城 ', 'start': '00:18:37,866', 'end': '00:18:40,577'}, {'index': 357, 'text': '外邊這也是城牆那一道叫做郭 ', 'start': '00:18:40,577', 'end': '00:18:43,247'}, {'index': 358, 'text': '那個老百姓就居住在那個郭裏邊 ', 'start': '00:18:43,288', 'end': '00:18:45,207'}, {'index': 359, 'text': '就是郭的那個裏邊 ', 'start': '00:18:45,207', 'end': '00:18:46,500'}, {'index': 360, 'text': '木蘭辭裏面出郭相扶將是吧 ', 'start': '00:18:46,750', 'end': '00:18:49,128'}, {'index': 361, 'text': '就會說這個郭 ', 'start': '00:18:49,128', 'end': '00:18:50,295'}, {'index': 362, 'text': '後來就指代城和城牆跟那個郭都指代同一個事情 ', 'start': '00:18:50,295', 'end': '00:18:54,758'}, {'index': 363, 'text': '但是古代的時候是用那個郭 ', 'start': '00:18:54,758', 'end': '00:18:56,760'}, {'index': 364, 'text': '那麼郭的外面呢 ', 'start': '00:18:56,760', 'end': '00:18:58,595'}, {'index': 365, 'text': '郭的外面叫做郊 ', 'start': '00:18:58,595', 'end': '00:19:00,556'}, {'index': 366, 'text': '我們現在說郊區啊是到郊區去啊 ', 'start': '00:19:00,848', 'end': '00:19:03,350'}, {'index': 367, 'text': '就是因為在那個城的外邊了 ', 'start': '00:19:03,350', 'end': '00:19:05,185'}, {'index': 368, 'text': '那個外邊叫做郊 ', 'start': '00:19:05,185', 'end': '00:19:06,603'}, {'index': 369, 'text': '這個郊的再外邊叫做野 ', 'start': '00:19:06,603', 'end': '00:19:09,106'}, {'index': 370, 'text': '就是比那個郊還要遠一點的地方那叫野 ', 'start': '00:19:09,106', 'end': '00:19:12,276'}, {'index': 371, 'text': '所以在武王伐紂的時候打的這場戰爭叫牧野之戰 ', 'start': '00:19:12,276', 'end': '00:19:16,780'}, {'index': 372, 'text': '對就是這個野這個野外的野那個叫做野 ', 'start': '00:19:16,780', 'end': '00:19:19,283'}, {'index': 373, 'text': '所以牧野之戰呢就是在野它是在野 ', 'start': '00:19:19,283', 'end': '00:19:23,453'}, {'index': 374, 'text': '這個地方是城外的郊郊外的野就在那個地方打的 ', 'start': '00:19:23,453', 'end': '00:19:26,874'}, {'index': 375, 'text': '所以這個桑林之野 ', 'start': '00:19:26,874', 'end': '00:19:27,958'}, {'index': 376, 'text': '然後以六事自責 ', 'start': '00:19:27,958', 'end': '00:19:29,918'}, {'index': 377, 'text': '說甚麼呢變不虛生 ', 'start': '00:19:29,918', 'end': '00:19:31,962'}, {'index': 378, 'text': '有天象變化了它不會憑空來的 ', 'start': '00:19:31,962', 'end': '00:19:34,590'}, {'index': 379, 'text': '必有感召 ', 'start': '00:19:35,048', 'end': '00:19:36,383'}, {'index': 380, 'text': '這個感召的意思就是天人相應 ', 'start': '00:19:36,383', 'end': '00:19:38,385'}, {'index': 381, 'text': '我們前面講過中華文化的核心嘛 ', 'start': '00:19:38,385', 'end': '00:19:40,762'}, {'index': 382, 'text': '感召是因為人事而感應了上天 ', 'start': '00:19:40,762', 'end': '00:19:45,934'}, {'index': 383, 'text': '人事有好的有壞的 ', 'start': '00:19:45,934', 'end': '00:19:48,020'}, {'index': 384, 'text': '好的上天會感應壞的上天也會有感應是吧 ', 'start': '00:19:48,020', 'end': '00:19:52,107'}, {'index': 385, 'text': '所以今天降災異以儆戒我 ', 'start': '00:19:52,107', 'end': '00:19:55,819'}, {'index': 386, 'text': '這個儆就是警告的意思 ', 'start': '00:19:55,819', 'end': '00:19:58,822'}, {'index': 387, 'text': '或者是我政令之出不能中節歟 ', 'start': '00:19:58,822', 'end': '00:20:01,909'}, {'index': 388, 'text': '中節就是中正不能夠中正 ', 'start': '00:20:01,909', 'end': '00:20:04,786'}, {'index': 389, 'text': '或使民無道失其職業歟 ', 'start': '00:20:05,204', 'end': '00:20:07,581'}, {'index': 390, 'text': '或者是所居的宮室過於崇高歟 ', 'start': '00:20:07,581', 'end': '00:20:10,709'}, {'index': 391, 'text': '或者是宮闈的婦女過於繁盛歟 ', 'start': '00:20:11,043', 'end': '00:20:15,797'}, {'index': 392, 'text': '這個他稍微做了一點 ', 'start': '00:20:16,215', 'end': '00:20:19,009'}, {'index': 393, 'text': '我剛才講的這個女謁的意思是那個 ', 'start': '00:20:19,009', 'end': '00:20:21,803'}, {'index': 394, 'text': '身邊那些進讒言的這些 ', 'start': '00:20:21,803', 'end': '00:20:24,598'}, {'index': 395, 'text': '就是古代的按照這個傳統 ', 'start': '00:20:24,598', 'end': '00:20:27,226'}, {'index': 396, 'text': '就是你是陰陽反背女人干政了 ', 'start': '00:20:27,226', 'end': '00:20:29,645'}, {'index': 397, 'text': '這不行是吧 ', 'start': '00:20:29,645', 'end': '00:20:30,812'}, {'index': 398, 'text': '但是張居正他說這個宮闈的婦女繁盛 ', 'start': '00:20:30,812', 'end': '00:20:35,609'}, {'index': 399, 'text': '是因為他稍微有一點顧忌 ', 'start': '00:20:35,609', 'end': '00:20:37,819'}, {'index': 400, 'text': '因為在那個時候皇帝是小還是小皇帝嘛 ', 'start': '00:20:37,819', 'end': '00:20:41,406'}, {'index': 401, 'text': '所以是太后是要垂簾聽政的 ', 'start': '00:20:41,406', 'end': '00:20:43,867'}, {'index': 402, 'text': '他不能就這麼明著說太后 ', 'start': '00:20:44,326', 'end': '00:20:46,745'}, {'index': 403, 'text': '他是跟小皇帝講課對不對 ', 'start': '00:20:46,745', 'end': '00:20:48,163'}, {'index': 404, 'text': '然後說你媽垂簾聽政不對是吧 ', 'start': '00:20:48,163', 'end': '00:20:50,457'}, {'index': 405, 'text': '這不行是吧 ', 'start': '00:20:50,457', 'end': '00:20:51,541'}, {'index': 406, 'text': '所以他就說是因為這個宮闈的婦女過於繁盛 ', 'start': '00:20:51,541', 'end': '00:20:54,920'}, {'index': 407, 'text': '或者是包苴之賄賂得行其營求歟 ', 'start': '00:20:56,004', 'end': '00:20:59,758'}, {'index': 408, 'text': '這個我們剛才講行賄 ', 'start': '00:20:59,758', 'end': '00:21:01,468'}, {'index': 409, 'text': '或者是造言生事的 ', 'start': '00:21:01,468', 'end': '00:21:03,136'}, {'index': 410, 'text': '這是進讒言的昌熾而害政歟 ', 'start': '00:21:03,136', 'end': '00:21:05,973'}, {'index': 411, 'text': '害政就是干政就是不好 ', 'start': '00:21:05,973', 'end': '00:21:08,100'}, {'index': 412, 'text': '有一干此則寧可降災於我一身 ', 'start': '00:21:08,100', 'end': '00:21:10,936'}, {'index': 413, 'text': '不可使百姓受厄 ', 'start': '00:21:10,936', 'end': '00:21:12,854'}, {'index': 414, 'text': '厄就是難的意思不能受災 ', 'start': '00:21:12,854', 'end': '00:21:15,399'}, {'index': 415, 'text': '商湯當時為此言就是當時說為就是形成 ', 'start': '00:21:15,399', 'end': '00:21:20,904'}, {'index': 416, 'text': '說完這句話一念至誠感動上天 ', 'start': '00:21:21,154', 'end': '00:21:23,907'}, {'index': 417, 'text': '沒說完呢說猶未了大雨即降 ', 'start': '00:21:23,907', 'end': '00:21:27,327'}, {'index': 418, 'text': '然後說方數千里之廣 ', 'start': '00:21:27,327', 'end': '00:21:29,496'}, {'index': 419, 'text': '中國古代的時候說這個長度單位 ', 'start': '00:21:30,747', 'end': '00:21:36,378'}, {'index': 420, 'text': '前面加一個方就變成面積單位了 ', 'start': '00:21:36,378', 'end': '00:21:38,797'}, {'index': 421, 'text': '我們平常說一里那麼是方數里方一里 ', 'start': '00:21:38,797', 'end': '00:21:42,968'}, {'index': 422, 'text': '那就是說是長和寬都是一里這樣的一個範圍 ', 'start': '00:21:42,968', 'end': '00:21:48,098'}, {'index': 423, 'text': '所以就是變成面積了 ', 'start': '00:21:48,098', 'end': '00:21:49,975'}, {'index': 424, 'text': '蓋人有善念天必從之 ', 'start': '00:21:49,975', 'end': '00:21:53,103'}, {'index': 425, 'text': '況人君為天子言一動上帝降臨 ', 'start': '00:21:53,103', 'end': '00:21:56,982'}, {'index': 426, 'text': '降臨呢就是降下來天象 ', 'start': '00:21:56,982', 'end': '00:21:59,192'}, {'index': 427, 'text': '轉災為祥乃理之必然也 ', 'start': '00:22:00,068', 'end': '00:22:03,488'}, {'index': 428, 'text': '本來是災是吧 ', 'start': '00:22:03,488', 'end': '00:22:04,489'}, {'index': 429, 'text': '在這個裏面祥是好的好的事情 ', 'start': '00:22:04,489', 'end': '00:22:08,994'}, {'index': 430, 'text': '祥瑞變成祥瑞了 ', 'start': '00:22:08,994', 'end': '00:22:11,038'}, {'index': 431, 'text': '這個裏邊剛才講了幾個注釋 ', 'start': '00:22:11,038', 'end': '00:22:14,583'}, {'index': 432, 'text': '一個是犧牲 ', 'start': '00:22:14,583', 'end': '00:22:15,625'}, {'index': 433, 'text': '一個是嬰這個嬰是纏繞的意思 ', 'start': '00:22:15,625', 'end': '00:22:17,961'}, {'index': 434, 'text': '這個女謁就是寵幸的女子 ', 'start': '00:22:17,961', 'end': '00:22:22,299'}, {'index': 435, 'text': '謁的意思就是進言 ', 'start': '00:22:22,299', 'end': '00:22:25,552'}, {'index': 436, 'text': '幫著皇帝領這個要說話要覲見的人那個叫謁 ', 'start': '00:22:25,552', 'end': '00:22:31,892'}, {'index': 437, 'text': '好這個就講到這兒 ', 'start': '00:22:33,852', 'end': '00:22:36,480'}, {'index': 438, 'text': '學生方數千里那是長寬都是數千里還是說總面積是數千里 ', 'start': '00:22:38,815', 'end': '00:22:44,988'}, {'index': 439, 'text': '這是個大概數 ', 'start': '00:22:44,988', 'end': '00:22:46,490'}, {'index': 440, 'text': '大概是你如果是面積 ', 'start': '00:22:46,948', 'end': '00:22:49,701'}, {'index': 441, 'text': '一個直徑是數千里 ', 'start': '00:22:49,701', 'end': '00:22:52,704'}, {'index': 442, 'text': '它的圓跟方的差別不是很大對不對 ', 'start': '00:22:52,704', 'end': '00:22:56,917'}, {'index': 443, 'text': '所以是大概是個大概數 ', 'start': '00:22:56,917', 'end': '00:22:58,627'}, {'index': 444, 'text': '學生問那這個是長度 ', 'start': '00:22:58,627', 'end': '00:23:01,088'}, {'index': 445, 'text': '長度的平方就是長度的平方 ', 'start': '00:23:01,088', 'end': '00:23:05,050'}, {'index': 446, 'text': '面積就長寬都是千里這樣的一個範圍就是 ', 'start': '00:23:07,135', 'end': '00:23:12,140'}, {'index': 447, 'text': '所以古代說就是方圓千里 ', 'start': '00:23:12,140', 'end': '00:23:14,518'}, {'index': 448, 'text': '意思就是說 ', 'start': '00:23:14,518', 'end': '00:23:15,852'}, {'index': 449, 'text': '方和圓差別的面積差別不大 ', 'start': '00:23:15,852', 'end': '00:23:18,105'}, {'index': 450, 'text': '四分之三大約是四分之三對不對 ', 'start': '00:23:18,105', 'end': '00:23:19,898'}, {'index': 451, 'text': '有個π嘛但是你是直徑直徑要除以四對不對四分之三 ', 'start': '00:23:19,898', 'end': '00:23:23,902'}, {'index': 452, 'text': '所以你是11或者是四分之三這麼多是吧差不多就是這樣的 ', 'start': '00:23:23,902', 'end': '00:23:29,282'}, {'index': 453, 'text': '它就意思當然不是那麼詳細了 ', 'start': '00:23:29,282', 'end': '00:23:32,744'}, {'index': 454, 'text': '大概只要是說方數千里或者是方圓數千里 ', 'start': '00:23:32,744', 'end': '00:23:36,581'}, {'index': 455, 'text': '意思就是說是大概這麼一個面積 ', 'start': '00:23:36,581', 'end': '00:23:38,834'}, {'index': 456, 'text': '大概面積長寬是數千里這樣的一個面積 ', 'start': '00:23:38,834', 'end': '00:23:42,754'}, {'index': 457, 'text': '就等於是天下當時旱的 ', 'start': '00:23:42,754', 'end': '00:23:46,633'}, {'index': 458, 'text': '當時湯所管轄直接管轄的那片地也就這麼大 ', 'start': '00:23:46,633', 'end': '00:23:51,430'}, {'index': 459, 'text': '所以他就說當時管轄這片地就都得到了旱災得到緩解 ', 'start': '00:23:51,430', 'end': '00:23:55,308'}], 'audio_filepath': ['/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.0._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.1._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.2._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.3._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.4._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.5._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.6._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.7._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.8._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.9._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.10._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.11._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.12._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.13._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.14._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.15._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.16._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.17._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.18._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.19._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.20._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.21._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.22._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.23._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.24._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.25._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.26._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.27._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.28._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.29._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.30._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.31._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.32._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.33._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.34._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.35._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.36._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.37._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.38._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.39._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.40._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.41._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.42._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.43._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.44._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.45._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.46._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.47._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.48._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.49._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.50._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.51._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.52._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.53._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.54._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.55._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.56._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.57._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.58._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.59._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.60._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.61._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.62._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.63._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.64._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.65._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.66._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.67._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.68._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.69._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.70._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.71._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.72._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.73._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.74._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.75._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.76._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.77._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.78._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.79._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.80._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.81._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.82._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.83._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.84._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.85._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.86._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.87._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.88._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.89._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.90._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.91._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.92._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.93._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.94._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.95._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.96._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.97._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.98._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.99._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.100._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.101._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.102._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.103._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.104._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.105._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.106._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.107._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.108._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.109._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.110._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.111._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.112._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.113._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.114._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.115._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.116._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.117._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.118._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.119._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.120._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.121._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.122._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.123._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.124._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.125._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.126._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.127._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.128._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.129._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.130._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.131._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.132._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.133._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.134._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.135._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.136._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.137._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.138._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.139._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.140._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.141._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.142._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.143._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.144._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.145._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.146._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.147._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.148._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.149._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.150._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.151._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.152._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.153._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.154._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.155._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.156._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.157._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.158._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.159._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.160._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.161._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.162._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.163._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.164._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.165._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.166._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.167._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.168._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.169._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.170._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.171._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.172._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.173._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.174._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.175._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.176._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.177._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.178._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.179._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.180._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.181._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.182._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.183._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.184._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.185._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.186._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.187._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.188._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.189._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.190._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.191._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.192._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.193._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.194._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.195._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.196._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.197._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.198._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.199._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.200._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.201._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.202._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.203._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.204._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.205._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.206._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.207._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.208._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.209._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.210._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.211._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.212._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.213._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.214._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.215._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.216._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.217._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.218._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.219._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.220._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.221._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.222._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.223._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.224._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.225._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.226._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.227._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.228._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.229._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.230._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.231._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.232._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.233._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.234._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.235._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.236._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.237._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.238._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.239._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.240._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.241._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.242._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.243._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.244._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.245._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.246._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.247._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.248._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.249._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.250._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.251._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.252._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.253._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.254._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.255._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.256._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.257._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.258._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.259._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.260._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.261._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.262._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.263._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.264._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.265._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.266._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.267._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.268._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.269._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.270._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.271._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.272._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.273._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.274._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.275._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.276._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.277._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.278._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.279._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.280._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.281._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.282._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.283._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.284._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.285._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.286._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.287._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.288._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.289._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.290._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.291._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.292._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.293._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.294._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.295._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.296._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.297._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.298._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.299._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.300._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.301._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.302._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.303._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.304._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.305._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.306._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.307._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.308._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.309._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.310._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.311._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.312._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.313._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.314._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.315._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.316._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.317._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.318._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.319._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.320._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.321._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.322._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.323._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.324._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.325._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.326._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.327._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.328._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.329._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.330._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.331._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.332._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.333._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.334._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.335._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.336._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.337._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.338._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.339._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.340._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.341._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.342._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.343._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.344._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.345._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.346._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.347._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.348._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.349._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.350._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.351._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.352._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.353._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.354._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.355._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.356._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.357._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.358._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.359._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.360._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.361._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.362._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.363._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.364._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.365._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.366._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.367._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.368._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.369._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.370._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.371._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.372._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.373._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.374._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.375._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.376._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.377._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.378._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.379._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.380._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.381._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.382._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.383._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.384._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.385._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.386._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.387._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.388._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.389._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.390._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.391._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.392._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.393._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.394._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.395._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.396._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.397._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.398._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.399._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.400._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.401._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.402._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.403._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.404._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.405._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.406._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.407._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.408._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.409._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.410._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.411._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.412._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.413._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.414._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.415._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.416._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.417._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.418._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.419._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.420._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.421._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.422._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.423._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.424._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.425._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.426._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.427._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.428._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.429._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.430._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.431._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.432._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.433._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.434._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.435._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.436._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.437._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.438._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.439._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.440._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.441._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.442._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.443._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.444._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.445._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.446._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.447._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.448._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.449._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.450._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.451._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.452._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.453._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.454._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.455._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.456._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.457._cut.wav', '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_cut/第10課-2-字幕版.458._cut.wav'], 'audio_files_subtitle_text': ['大家看那個章天亮教授那個笑談風雲裏面 ', '他前面講了這個三場大風造成改變了中國的歷史 ', '這都是真實的事情 ', '那我再補充一個 ', '當時就是明太祖跟陳友諒大戰的時候 ', '那劉伯溫是明太祖朱元璋的軍師嘛 ', '他們在鄱陽湖大戰的時候呢正打得激烈的時候 ', '是船就是用船打所以他們是坐在船上 ', '劉伯溫呢突然大叫說突然在那兒使勁揮手 ', '朱元璋還以為劉伯溫突然在戰爭中臨場反叛了呢 ', '還嚇了一跳 ', '結果劉伯溫就在那大喊他說難星過急更舟 ', '就是這個難星過甚麼意思呢 ', '他觀測到天上有難星難就有災了 ', '趕快換趕快換船 ', '所以朱元璋就聽他的話了趕快換船 ', '剛換完船然後一個炮那時候是已經發明火藥了有炮 ', '一個炮過來就把原來那個船給炸沉了炸碎了一下就炸碎了 ', '所以這個是當時劉伯溫看到的 ', '中國的歷史上每一朝每一代 ', '這些幫助帝王打天下的都有一些修煉的人 ', '很多是道士也有一些和尚 ', '那麼這些和尚呢 ', '我們從最開始武王伐紂的時候我們就看到了 ', '看這個封神演義裏面那都修道修煉人都出來是不是 ', '所以在人世間來幫這些天子 ', '他們該打天下了該改朝換代了 ', '來幫助人間來做一些事情 ', '所以這個劉伯溫當時其實就是起這個作用 ', '如果是他朱元璋不換的話這個中國的歷史就改了是吧 ', '就不是朱元璋也不是明朝了是吧 ', '所以這種事情在中國的歷史上也是非常多的 ', '我們剛才講這些其實就是說人類的歷史並不是說 ', '我們講哪怕這個唯物歷史觀說是到了甚麼時候叫做時勢造英雄 ', '說到這個時候了該出一個英雄了 ', '然後因為這件事情到這了 ', '所以就有一個英雄他就能夠發揮作用 ', '其實是反過來是反過來的 ', '那個英雄其實他是起的是關鍵作用 ', '而中國人的傳統的歷史觀是說 ', '這個英雄呢是上天派他來的 ', '他該做天子他該建立一個王朝 ', '他該做甚麼事情所以上天派他來 ', '那所有的天象都跟著變 ', '人世間的事人間的事情也跟著安排 ', '也會發生變化都隨著他來 ', '所以正好是相反 ', '但是西方在十八世紀的時候 ', '有一度曾經也流行過這個歷史觀叫做英雄史觀 ', '這個英雄史觀是怎麼說的呢 ', '這個是ThomasCarlyle湯瑪斯卡萊爾 ', '他是ScottishPhilosopherScottishHistorianandPhilosopher ', '他是蘇格蘭的哲學家和歷史學家 ', '那麼他寫了一本書叫 ', 'OnHeroesHeroWorshipandtheHeroicinHistory 關於英雄英雄崇拜和英雄主義 ', 'Heroic就是英雄主義現在叫它英雄主義 ', '他說甚麼呢 ', '他說歷史上的那些事情啊所完成的那些豐功偉績啊 ', '其實都是來自於外部的這個outermaterial ', '來自外部的這些力量在人間實現 ', '在人間怎麼實現呢 ', '那個外部的力量在人間派一個英雄 ', '把那些idea想法告訴那些人就是注到他這個腦子裏 ', '然後在人間實現 ', '其實他的觀點跟中國傳統的觀點是非常接近的 ', '所以他就說我們現在看到的是甚麼 ', '是outermaterialresult ', '是那些外部的力量造成的結果 ', '然後thepracticalrealisationandembodiment ', '我們現在現實中的這些實現啊 ', '從甚麼實現呢 ', 'theThoughtsthatdweltintheGreatMansentintotheworld 被派到人間的偉人驅動他們的思想成就了現實 ', '那些偉人啊他們是sentintotheworld ', '他們是上天派他們來到這個人世間 ', '所以這個史觀在十八世紀的時候 ', '還是跟中國的傳統的史觀是吻合的 ', '但是後來西方和中國的史學家觀點都已經完全不一樣了 ', '現在呢就是純粹從物質的角度來解釋了 ', '那麼我們講了我們前面講過 ', '中國傳統史觀裏邊有一個很重要 ', '一個是它承傳價值我們前面講過了 ', '上明三王之道下辨人事之紀是不是 ', '善善惡惡大家還記得嗎我們前面講過是不是 ', '賢賢賤不肖 ', '所以這個歷史把善的惡的好的壞的都呈現出來 ', '而且有一個評價我們就可以作為參照是吧 ', '還有一個呢叫究天人之際 ', '這是司馬遷寫的究天人之際通古今之變 ', '這是他寫史記的時候 ', '那後世的史觀繼承了這個思想是吧 ', '究天人之際就是要探究天和人之間的關係是吧 ', '那麼從這個歷史中怎麼樣體現出天和人的關係 ', '怎麼樣探究出天和人的關係呢 ', '我們就在講這個概述歷史之前呢 ', '給大家做一個簡要的敘述 ', '我先講一個例子就是這個桑林禱雨 ', '這個是帝鑑圖說裏面的 ', '這件事情是發生在商朝 ', '商朝大家知道開創是商湯 ', '我們平常講這個三王啊其中就有商湯 ', '商湯文王有時候把這個武王也包含在裏面 ', '那麼有時候是把這個大禹放在裏邊 ', '這就是上古的聖王商湯 ', '商湯在位的時候有一次大旱 ', '這個事情是在不同的史書上都有記載 ', '那麼這個帝鑑圖說採用的是淮南子裏面的 ', '我們上回講過淮南子是中國圖書集成 ', '那個淮南王劉安他召集手下的門客 ', '把這八千多部書蒐集起來把它們的內容總和在裏邊的 ', '那這個事情呢在呂氏春秋裏面也有 ', '那麼記載會稍微有一點的差別 ', '那麼在商朝的時候就是商湯繼位以後天下大旱 ', '那我們講了這個天下大旱像這種 ', '這是上天降下來的一個信號 ', '這叫災或者是祥 ', '這個祥就是祥瑞的祥 ', '所以這個災或者是祥或者是祥瑞或者是災異 ', '這都叫祥詳那就是上天降下來的異象是天象 ', '那麼怎麼辦呢 ', '商湯就說我要為萬民祈禱向上天求雨 ', '他就要登上祭壇上去求雨 ', '那麼他去求雨的時候開始占卜的人說 ', '你啊應該要犧牲 ', '這個犧牲這個詞 ', '我們現在說犧牲是共產黨說那個甚麼烈士犧牲 ', '以前這個犧牲是祭祀的時候 ', '把豬啊或牛啊獻給上天或者祖宗那個叫犧牲 ', '所以祭祀的這個動物這個動物叫犧牲 ', '那麼他就說呢需要一個人來犧牲 ', '一個人來作為犧牲給這個上天祭祀才能夠祭祀成功 ', '因為七年大旱啊其實不是說這一次才禱雨 ', '前面都祈禱過很多次都不行嘛 ', '所以這個占卜呢就說你要誠心 ', '而且要以人來祭祀才行 ', '那後來這個商湯就說以人祭祀我本來就是為萬民祈禱是吧 ', '要以人祭祀呢這個我於心不忍 ', '但是上天如果說確實是需要人來祭祀呢 ', '那我也是人嘛就拿我來吧 ', '就說讓我來做這個犧牲 ', '所以他就自己齋戒然後沐浴 ', '然後換上恭恭敬敬的這個叫做身纏白茅那個白色的茅草 ', '然後就指甲剪掉頭髮弄掉然後恭恭敬敬到這個祭壇上 ', '就以七六件事情來自責 ', '說上天不下雨啊如果是因為有甚麼原因呢 ', '歸罪都在我身上不要歸罪萬民不要歸罪其他的人 ', '有罪的是我因為我是上天派下來的天子是吧 ', '所以我有責任 ', '那麼我呢是不是以下七六件事情沒有做好 ', '所以他就列六件事情沒有做好 ', '所以他說呢 ', '第一個呢是不是我的政事 ', '我這個安排啊朝政安排的不合適 ', '是不是或者是百姓流離失所 ', '是不是宮室我營建的宮室太過繁華了 ', '或者是不是這個後宮啊 ', '後宮裏邊這些女人刮枕邊風 ', '就是說這個干涉朝政就像妲己一樣是不是有這樣的事情 ', '或者呢是不是有這個小人進讒言 ', '說完了以後呢他就準備要去點火了 ', '就在這個時候突然一場大雨下來 ', '然後方圓幾千里地都是大雨 ', '一下就把這個旱災就解了 ', '這個是記載在史書上 ', '我們剛才講了在淮南子和在呂氏春秋裏邊都有 ', '但是這兩個裏面說的不一樣 ', '呂氏春秋裏面是說七年大旱 ', '淮南子呢是說五年大旱 ', '但這個不是大的問題 ', '就是說確實有這麼一件事情 ', '那後來呢因為這場大雨 ', '這個老百姓就感恩嘛 ', '所以後來商朝就傳下來一首樂舞 ', '這個樂舞呢就叫桑林之舞 ', '就是這個桑林他們祭祀的這個地方叫桑林這是地名 ', '後來傳下來這個樂舞就叫桑林之舞 ', '這個桑林之舞是上古三代的時候傳下來的非常有名的 ', '那後來這個傳統 ', '就是這個桑林之舞這樣的樂舞它幹甚麼呢 ', '做兩件事情一個是感恩上天一個是歌頌商湯的功德 ', '所以我們後來就有一個成語叫做歌功頌德 ', '歌功頌德是這個意思 ', '現在說歌功頌德是反的 ', '以前的歌功頌德是這個意思 ', '是他的德行他的功績然後呢感恩上天 ', '所以為甚麼要傳這個 ', '這個中國禮樂文化禮樂文明 ', '這個樂和舞是連在一起的這是禮樂文明 ', '這個是在我們禮樂文化裏面很重要的桑林之舞 ', '好我給大家過一下這個解釋一下 ', '這個應該不難 ', '那他說這個 ', '這是上回我們講的這個帝鑑圖說 ', '他說商史紀成湯時成湯就是商湯 ', '歲久大旱太史占之曰 ', '太史就是太史我們上回講過他又是史官又是天文官 ', '所以這個太史他占卜說應該以人禱 ', '禱是祈禱或者祭祀那麼應該用人來祈禱 ', '那商湯就說吾所以請雨者人也 ', '我是為人來求雨的 ', '若必以人如果必須要用人來作為犧牲呢 ', '那吾請自當我就自己來吧用我自己 ', '遂齋戒剪髮斷爪 ', '這個爪的意思就是那個指甲 ', '不是那個爪 ', '我們說那個爪那是動物以前說這個爪是指甲 ', '素車白馬 ', '這是你要祭祀嘛 ', '所以素車就是不能有任何裝飾的車和白馬 ', '身嬰白茅身上纏上身嬰白茅就是身上纏那個白色的茅草 ', '以為犧牲我們剛剛才講這個犧牲 ', '禱於桑林之野 ', '那麼以六件事情來問責自己 ', '是問上蒼實際上是跟上蒼 ', '說是不是我以下這些事情做的不對 ', '第一件事政不節歟 ', '這個歟是語氣詞就是相當於嗎 ', '那我的政事做的不好不夠節制 ', '民失職歟是不是老百姓啊他們 ', '失職就是老百姓他們不能夠安居樂業 ', '我們現在話講就是不能夠安居樂業 ', '那就是老百姓流離失所嘛 ', '然後第三個他說宮室崇歟 ', '崇就是奢華高大是吧 ', '營建宮室 ', '大家知道那個商紂王 ', '他就是營建那個高臺啊營建富麗堂皇的宮殿啊 ', '凡是這些亡國之君一般都喜歡幹這些事情 ', '所以他說是不是因為這個呢 ', '或者是女謁盛歟這個謁的意思是覲見 ', '就是說你要覲見一個皇上下級要見上級這叫謁 ', '那麼你要去覲見皇上那有一個人要引薦你啊 ', '那個引薦的人帶你的那個人 ', '那個導引你的那個人那叫謁者 ', '那這個女謁的意思是甚麼呢 ', '女謁盛歟呢是我想要做一件甚麼事情 ', '我想跟皇帝說一件事情或者是想覲見 ', '一個壞人想進讒言跟皇帝進讒言 ', '你不能夠想見皇帝就見到了對不對 ', '所以這種人他可能就會去找那個後宮找那個嬪妃 ', '讓她們來跟皇帝來說這種情況就叫女謁 ', '就是嬪妃她們在這個皇帝面前進讒言做不好 ', '所以這種情況是屬於就跟妲己禍亂朝廷一樣 ', '妲己不是就幹壞事嗎 ', '所以這種情況就屬於是陰陽反背 ', '這個在傳統的禮法中女人是不能干政的 ', '所以呢它是就是跟妲己一樣這個也是亡國之兆是吧 ', '女謁盛歟這個盛是這種情況很多盛就是很興盛嘛 ', '包苴行歟這個包苴是賄賂的意思 ', '就是我們現在行賄受賄這個古代叫包苴 ', '為甚麼叫包苴呢 ', '這個苴是一種草是一種茅草 ', '包苴呢就是我要送你一個禮物啊 ', '那我一般來說就是 ', '你看大家是現在你買一個禮物 ', '它還有個Wrap包裝很漂亮 ', '給你一個包裝把那個禮物包起來 ', '人家一看這是一個很好的東西是吧 ', '古代是反過來的是因為表示謙虛 ', '我送你一個東西然後我就說哎呀這個沒甚麼東西 ', '這個一點小意思笑納吧 ', '所以他就送你哪怕是好東西我也說這個是不好對不對 ', '所以一般來說它不會有這種包 ', '但是也有一種情況要把它包起來 ', '甚麼樣情況包起來呢 ', '你要行賄的時候你把它包起來 ', '因為你不想讓別人知道你在行賄嘛 ', '所以你行賄的時候呢拿茅草把它包起來 ', '那茅草人家說你還送了一個茅草是吧 ', '這個其實沒甚麼東西裏面可能是金銀財寶是吧 ', '所以這個後來就演變成這個詞 ', '就包苴的意思就是說是行賄 ', '所以讒夫 ', '讒夫就是進讒言的這種人 ', '昌很昌盛是吧昌歟 ', '說還沒說完呢大雨方數千里 ', '方是方圓方圓數千里 ', '這個張居正給小皇帝後面的解啊 ', '這個它是說解釋是說甚麼 ', '商史上記 ', '這個就比較容易理解了 ', '成湯之時歲久不雨天下大旱 ', '靈臺靈臺官 ', '靈臺官就是這個天文官 ', '觀天象的這個臺啊這個天文臺叫做靈臺 ', '所以這個靈臺官的意思就是這個天文官 ', '天文官這個太史太史占候 ', '這個靈臺在這個古書上裏面記載 ', '就是我們現在看的 ', '就是如果你要看這個封神演義裏面就有 ', '這個老百姓幫著周文王修建那個靈臺 ', '因為周文王說我要觀天象是吧要修建靈臺 ', '然後這個老百姓一聽踴躍幫忙 ', '所以就開始挖土啊幹嘛去修這個靈臺很快就成了 ', '結果還出現一件事情 ', '挖挖挖突然挖出來三具幾具枯骨 ', '這死人的枯骨 ', '然後那些人就說這個荒郊野外不知道是誰的 ', '這些枯骨就這樣扔了吧 ', '當時那個周文王說 ', '這個枯骨咱們要把它好好的厚葬 ', '好好的埋葬起來恭恭敬敬埋葬起來 ', '那底下的人說這個又不知道它是誰的枯骨是吧 ', '那周文王就說 ', '這個枯骨在我的地盤上那就是我的子民 ', '所以他們沒有能夠得到很好的安葬是我的責任 ', '就應該把他們 ', '我應該盡我的責任給他們很好的安葬 ', '所以後來這個老百姓就傳頌說這個周文王啊澤及枯骨 ', '他的那個恩惠啊 ', '連這個枯骨都能夠受到恩惠是吧 ', '所以這個天下就歸順了周文王 ', '當然那個時候就是靈臺 ', '你要如果看那個西遊記裏面它也說這個靈臺 ', '大家有記得西遊記裏面說靈臺嗎 ', '這個裏面 ', '那個孫悟空去拜師父的時候 ', '拜那個菩提老祖的時候 ', '去的那個地方那個山叫靈臺山 ', '斜月三星洞 ', '那個靈臺 ', '斜月三星洞大家知道吧 ', '是個心字靈臺呢同時又也可以指心 ', '在中國這個傳統裏面這個靈臺也可以表示心 ', '所以這個靈臺官占候 ', '這個候就是天象 ', '這個候候甚麼候天象 ', '說呢這旱災須是殺個人祈禱乃得雨 ', '他才能夠求到雨 ', '成湯就說我所以求雨呢就是要救濟活人 ', '生人是活人 ', '又豈忍殺人以為禱乎 ', '如果必須要用人來 ', '那寧可我自己來吧 ', '當就是抵當就是比如我們到當鋪是吧 ', '大家知道那個當鋪吧聽說過吧 ', '就是你缺錢了你得拿個東西拿戒指去換一些錢嘛 ', '就是典當嘛所以這個當呢就是換的意思 ', '就拿我來換祈禱這個人 ', '當是這個意思 ', '然後遂齋戒身心剪斷爪髮 ', '素車白馬減損服禦 ', '這個因為皇帝出車它是有禮嘛 ', '減損就是不要穿啊這些包括裝飾啊 ', '都要減損 ', '身上披著白茅草 ', '就如祭祀的犧牲模樣 ', '我剛才講的這個犧牲 ', '乃出禱於桑林之野 ', '這個桑林之野 ', '這個我們講這個野是甚麼意思呢 ', '不是野外 ', '古代的時候呢那個城啊我們現在叫城 ', '還有一個詞叫做城郭大家知道吧 ', '這個城郭是兩道城牆 ', '裏邊的那個叫城外邊的這一道叫做郭 ', '裏邊的皇帝居住的那個城啊那個是城 ', '外邊這也是城牆那一道叫做郭 ', '那個老百姓就居住在那個郭裏邊 ', '就是郭的那個裏邊 ', '木蘭辭裏面出郭相扶將是吧 ', '就會說這個郭 ', '後來就指代城和城牆跟那個郭都指代同一個事情 ', '但是古代的時候是用那個郭 ', '那麼郭的外面呢 ', '郭的外面叫做郊 ', '我們現在說郊區啊是到郊區去啊 ', '就是因為在那個城的外邊了 ', '那個外邊叫做郊 ', '這個郊的再外邊叫做野 ', '就是比那個郊還要遠一點的地方那叫野 ', '所以在武王伐紂的時候打的這場戰爭叫牧野之戰 ', '對就是這個野這個野外的野那個叫做野 ', '所以牧野之戰呢就是在野它是在野 ', '這個地方是城外的郊郊外的野就在那個地方打的 ', '所以這個桑林之野 ', '然後以六事自責 ', '說甚麼呢變不虛生 ', '有天象變化了它不會憑空來的 ', '必有感召 ', '這個感召的意思就是天人相應 ', '我們前面講過中華文化的核心嘛 ', '感召是因為人事而感應了上天 ', '人事有好的有壞的 ', '好的上天會感應壞的上天也會有感應是吧 ', '所以今天降災異以儆戒我 ', '這個儆就是警告的意思 ', '或者是我政令之出不能中節歟 ', '中節就是中正不能夠中正 ', '或使民無道失其職業歟 ', '或者是所居的宮室過於崇高歟 ', '或者是宮闈的婦女過於繁盛歟 ', '這個他稍微做了一點 ', '我剛才講的這個女謁的意思是那個 ', '身邊那些進讒言的這些 ', '就是古代的按照這個傳統 ', '就是你是陰陽反背女人干政了 ', '這不行是吧 ', '但是張居正他說這個宮闈的婦女繁盛 ', '是因為他稍微有一點顧忌 ', '因為在那個時候皇帝是小還是小皇帝嘛 ', '所以是太后是要垂簾聽政的 ', '他不能就這麼明著說太后 ', '他是跟小皇帝講課對不對 ', '然後說你媽垂簾聽政不對是吧 ', '這不行是吧 ', '所以他就說是因為這個宮闈的婦女過於繁盛 ', '或者是包苴之賄賂得行其營求歟 ', '這個我們剛才講行賄 ', '或者是造言生事的 ', '這是進讒言的昌熾而害政歟 ', '害政就是干政就是不好 ', '有一干此則寧可降災於我一身 ', '不可使百姓受厄 ', '厄就是難的意思不能受災 ', '商湯當時為此言就是當時說為就是形成 ', '說完這句話一念至誠感動上天 ', '沒說完呢說猶未了大雨即降 ', '然後說方數千里之廣 ', '中國古代的時候說這個長度單位 ', '前面加一個方就變成面積單位了 ', '我們平常說一里那麼是方數里方一里 ', '那就是說是長和寬都是一里這樣的一個範圍 ', '所以就是變成面積了 ', '蓋人有善念天必從之 ', '況人君為天子言一動上帝降臨 ', '降臨呢就是降下來天象 ', '轉災為祥乃理之必然也 ', '本來是災是吧 ', '在這個裏面祥是好的好的事情 ', '祥瑞變成祥瑞了 ', '這個裏邊剛才講了幾個注釋 ', '一個是犧牲 ', '一個是嬰這個嬰是纏繞的意思 ', '這個女謁就是寵幸的女子 ', '謁的意思就是進言 ', '幫著皇帝領這個要說話要覲見的人那個叫謁 ', '好這個就講到這兒 ', '學生方數千里那是長寬都是數千里還是說總面積是數千里 ', '這是個大概數 ', '大概是你如果是面積 ', '一個直徑是數千里 ', '它的圓跟方的差別不是很大對不對 ', '所以是大概是個大概數 ', '學生問那這個是長度 ', '長度的平方就是長度的平方 ', '面積就長寬都是千里這樣的一個範圍就是 ', '所以古代說就是方圓千里 ', '意思就是說 ', '方和圓差別的面積差別不大 ', '四分之三大約是四分之三對不對 ', '有個π嘛但是你是直徑直徑要除以四對不對四分之三 ', '所以你是11或者是四分之三這麼多是吧差不多就是這樣的 ', '它就意思當然不是那麼詳細了 ', '大概只要是說方數千里或者是方圓數千里 ', '意思就是說是大概這麼一個面積 ', '大概面積長寬是數千里這樣的一個面積 ', '就等於是天下當時旱的 ', '當時湯所管轄直接管轄的那片地也就這麼大 ', '所以他就說當時管轄這片地就都得到了旱災得到緩解 ']}\n"]}],"source":["import json\n","\n","# Opening JSON file\n","with open('/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/srt_subtitles_json.json', 'r') as openfile:\n","\n","\t# Reading from json file\n","\tsrt_subtitles = json.load(openfile)\n","\n","print(type(srt_subtitles))\n","print(srt_subtitles.keys())\n","print(srt_subtitles[next(iter(srt_subtitles.keys()))].keys())\n","print(srt_subtitles[next(iter(srt_subtitles.keys()))])\n"]},{"cell_type":"code","execution_count":null,"id":"RUYeFU-DmKUq","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1704675814158,"user":{"displayName":"Ian Liu","userId":"10053214275715814514"},"user_tz":300},"id":"RUYeFU-DmKUq","outputId":"123d58ae-60d5-4720-e676-ade0b1658466"},"outputs":[{"data":{"text/plain":["['第10課-2',\n"," '第10課-4',\n"," '第13課-4',\n"," '第11課-4',\n"," '第2課-2',\n"," '第10課-1',\n"," 'CLC014-1',\n"," '第12课-4',\n"," '第11課-1',\n"," '第3課-3',\n"," 'CLC015-2',\n"," '第13課-1',\n"," '第7課-3',\n"," '第4課-2',\n"," '第2課-1',\n"," '第5課-2',\n"," '第6課-1',\n"," '第8課-1',\n"," '第12课-3',\n"," '第4課-1',\n"," '第2課-3',\n"," 'CLC014-2',\n"," '第9課-2',\n"," 'CLC015-1',\n"," '第7課-1',\n"," '第8課-4',\n"," '第6課-3',\n"," '第9課-3',\n"," '第8課-2',\n"," 'CLC014-3',\n"," '第5課-1',\n"," '第11課-3',\n"," '第3課-1',\n"," '第13課-3',\n"," '第11課-2',\n"," '第3課-2',\n"," '第13課-2',\n"," '第6課-2',\n"," '第12课-1',\n"," '第12课-2',\n"," '第9課-1',\n"," 'CLC015-3']"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["finished"]},{"cell_type":"code","execution_count":null,"id":"0PRKEsTekMdv","metadata":{"id":"0PRKEsTekMdv"},"outputs":[],"source":["files_left = ['第6課-1']"]},{"cell_type":"code","execution_count":null,"id":"0r_x0dELherY","metadata":{"id":"0r_x0dELherY"},"outputs":[],"source":["all_wav_files = set(os.listdir(wav_folder))\n","all_srt_files = set(os.listdir(srt_folder))\n","all_srt_files = [i for i in all_srt_files if i.endswith('.srt')]\n","all_wav_files = [i for i in all_wav_files if i.endswith('.wav')]\n","\n","for srt_file in all_srt_files:\n","  if not srt_file.endswith('.srt'):\n","    continue\n","\n","  srt_path = os.path.join(srt_folder, srt_file)\n","\n","  lecture_name = \"-\".join( srt_file.split(\"-\")[:2])\n","\n","  if '.srt' in lecture_name:\n","    lecture_name = lecture_name.split('.srt')[0]\n","\n","  lecture_name = lecture_name.strip()\n","\n","  # if lecture_name in finished:\n","  #   continue\n","  if lecture_name not in files_left:\n","    continue\n","  elif srt_subtitles.get(lecture_name) is not None:\n","    print(f\"{srt_file} already has SRT stored?\")\n","    print(f\"overwriting {srt_file}\")\n","\n","  subtitles = read_srt(srt_path)\n","  print(subtitles[0])\n","  print(subtitles[1])\n","\n","\n","  srt_subtitles[lecture_name] = {}\n","  srt_subtitles[lecture_name]['srt_filepath'] = srt_path\n","  srt_subtitles[lecture_name]['subtitles'] = subtitles\n","  srt_subtitles[lecture_name]['audio_filepath'] =  []\n","  srt_subtitles[lecture_name]['audio_files_subtitle_text'] =  []\n","\n","  # We are Loop through all mp4 files in the folder\n","  for wav_file_indx, wav_file in enumerate(all_wav_files):\n","\n","    if not wav_file.endswith('.wav'):\n","      continue\n","\n","    wav_lecture_name = \"-\".join( wav_file.split(\"-\")[:2] )\n","    wav_lecture_name = wav_lecture_name.strip()\n","\n","    if wav_lecture_name != lecture_name:\n","      if wav_file_indx  >= len(all_wav_files) - 1:\n","        print(\"FAILURE,\" + lecture_name +  \" could not be found \" + wav_lecture_name)\n","      continue\n","\n","\n","    wav_path = os.path.join(wav_folder, wav_file)\n","\n","\n","\n","    for subtitle_indx, subtitle in enumerate(subtitles):\n","      start_seconds = timestamp_to_seconds(subtitle[\"start\"])\n","      end_seconds = timestamp_to_seconds(subtitle[\"end\"])\n","\n","      start_seconds -= 0.5\n","      end_seconds += 0.5\n","      start_seconds = max(start_seconds, 0)\n","      start_seconds = max(start_seconds, 0)\n","\n","\n","      difference = end_seconds - start_seconds\n","      if not isinstance(difference,(int, float)) or  not isinstance(start_seconds,(int, float)):\n","        print(start_seconds, type(start_seconds), difference, type(difference), wav_path)\n","        continue\n","\n","\n","\n","      cut_wav_file = os.path.splitext(wav_file)[0] + f'.{subtitle_indx}._cut.wav'\n","      cut_wav_path = os.path.join(cut_wav_folder, cut_wav_file)\n","\n","\n","\n","      cut_command = f\"ffmpeg -i '{wav_path}' -ss {start_seconds} -t {difference} '{cut_wav_path}'\"\n","      subprocess.run(cut_command, shell=True)\n","\n","      srt_subtitles[lecture_name]['audio_filepath'].append(cut_wav_path)\n","      srt_subtitles[lecture_name]['audio_files_subtitle_text'].append(subtitle['text'])\n","\n","      # print(f\"Cut {wav_path} to {cut_wav_file} for subtitle {subtitle['index']}\")\n","\n","    print(\"SUCCESS: \", wav_lecture_name)\n","    break\n"]},{"cell_type":"code","execution_count":null,"id":"60jQ9wpReUH5","metadata":{"id":"60jQ9wpReUH5"},"outputs":[],"source":["\n","srt_subtitles_json_obj = json.dumps(srt_subtitles, indent=4)\n","\n","with open(\"/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/srt_subtitles_json.json\", \"w\") as outfile:\n","\toutfile.write(srt_subtitles_json_obj)\n"]},{"cell_type":"markdown","id":"805b1c56","metadata":{"id":"805b1c56"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":null,"id":"-nZjyBWNdYLj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":691,"status":"ok","timestamp":1704837446252,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"-nZjyBWNdYLj","outputId":"1e46f607-7c0d-4869-828e-b52f0d6a7680"},"outputs":[{"name":"stdout","output_type":"stream","text":["18399 2961\n","18395 2960\n"]}],"source":["test_subtitles_text = []\n","test_subtitles_audio = []\n","train_subtitles_text = []\n","train_subtitles_audio = []\n","\n","for lecture_name, lecture_dict in srt_subtitles.items():\n","  if \"CLC014\" in lecture_name or \"CLC015\" in lecture_name:\n","    for indx, subtitle_text in enumerate(lecture_dict['audio_files_subtitle_text']):\n","      test_subtitles_text.append(subtitle_text)\n","      test_subtitles_audio.append(lecture_dict.get('audio_filepath')[indx])\n","    continue\n","\n","  for indx, subtitle_text in enumerate(lecture_dict['audio_files_subtitle_text']):\n","    train_subtitles_text.append(subtitle_text)\n","    train_subtitles_audio.append(lecture_dict.get('audio_filepath')[indx])\n","\n","test_subtitles_text = [i.strip() for i in test_subtitles_text]\n","test_subtitles_audio = [i.strip() for i in test_subtitles_audio]\n","test_subtitles_audio = [i.split('/')[-1] for i in test_subtitles_audio]\n","test_subtitles_audio = [os.path.join('data/test',i) for i in test_subtitles_audio]\n","\n","train_subtitles_text = [i.strip() for i in train_subtitles_text]\n","train_subtitles_audio = [i.strip() for i in train_subtitles_audio]\n","train_subtitles_audio = [i.split('/')[-1] for i in train_subtitles_audio]\n","train_subtitles_audio = [os.path.join('data/train',i) for i in train_subtitles_audio]\n","assert(len(test_subtitles_text) == len(test_subtitles_audio))\n","assert(len(train_subtitles_text) == len(train_subtitles_audio))\n","print(len(train_subtitles_audio), len(test_subtitles_audio))\n","print(len(glob.glob(training_folder + '/*')), len(glob.glob(testing_folder + '/*')))"]},{"cell_type":"code","execution_count":null,"id":"FjnQ8k5Eebpz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1704837448580,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"FjnQ8k5Eebpz","outputId":"25764749-4130-4a36-8575-ec931b81b27b"},"outputs":[{"name":"stdout","output_type":"stream","text":["18395 2960\n"]}],"source":["print(len(os.listdir(training_folder)), len(os.listdir(testing_folder)))"]},{"cell_type":"code","execution_count":null,"id":"KVRs0rGDeUS5","metadata":{"id":"KVRs0rGDeUS5"},"outputs":[],"source":["all_subtitles_text = train_subtitles_text + test_subtitles_text\n","all_subtitles_audio = train_subtitles_audio + test_subtitles_audio\n","assert(len(all_subtitles_text) == len(all_subtitles_audio))"]},{"cell_type":"code","execution_count":null,"id":"XajcXbCShH0G","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1704825500373,"user":{"displayName":"Ian Liu","userId":"10053214275715814514"},"user_tz":300},"id":"XajcXbCShH0G","outputId":"5a732d38-87f7-469d-d205-406ad47a92c2"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'data/test/CLC014-2-字幕版.56._cut.wav'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["'/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/test/CLC014-2-字幕版.56._cut.wav'.split('WAV_train_test_split/')[-1]"]},{"cell_type":"code","execution_count":null,"id":"aQAruBPU2LOm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17923,"status":"ok","timestamp":1704837471332,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"aQAruBPU2LOm","outputId":"7fca7440-c72d-4ed1-ba99-7f8bead0a452"},"outputs":[{"name":"stdout","output_type":"stream","text":["data/train/第10課-1-字幕版.129._cut.wav\n","Removed data/train/第10課-1-字幕版.129._cut.wav, \n","data/train/第4課-1-片頭片尾字幕版.115._cut.wav\n","Removed data/train/第4課-1-片頭片尾字幕版.115._cut.wav, \n","data/train/第9課-3-字幕版.113._cut.wav\n","Removed data/train/第9課-3-字幕版.113._cut.wav, \n","data/train/第9課-4-字幕版.193._cut.wav\n","Removed data/train/第9課-4-字幕版.193._cut.wav, \n","data/test/CLC014-2-字幕版.300._cut.wav\n","Removed data/test/CLC014-2-字幕版.300._cut.wav, \n"]}],"source":["all_training_files = glob.glob(training_folder + '/*')\n","all_testing_files = glob.glob(testing_folder + '/*')\n","all_training_files = [i.split('WAV_train_test_split/')[-1] for i in all_training_files]\n","all_testing_files = [i.split('WAV_train_test_split/')[-1] for i in all_testing_files]\n","all_training_files = list(set(all_training_files))\n","all_testing_files = list(set(all_testing_files))\n","\n","for indx, i_file in enumerate(all_subtitles_audio):\n","  if i_file not in all_training_files and i_file not in all_testing_files:\n","    print(i_file)\n","\n","  if i_file == \"\" or i_file is None or all_subtitles_text[indx] == \"\" or all_subtitles_text is None:\n","    print(f\"Removed {i_file}, {all_subtitles_text[indx]}\")\n","    all_subtitles_text.pop(indx)\n","    all_subtitles_audio.pop(indx)\n"]},{"cell_type":"code","execution_count":null,"id":"mzomtLpu1---","metadata":{"id":"mzomtLpu1---"},"outputs":[],"source":["!rm -rf '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/test/CLC014-2-字幕版.300._cut.wav'\n","!rm -rf '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/train/第9課-3-字幕版.113._cut.wav'\n","!rm -rf '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/train/第9課-4-字幕版.193._cut.wav'\n","!rm -rf '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/train/第4課-1-片頭片尾字幕版.115._cut.wav'\n","!rm -rf '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/train/第10課-1-字幕版.129._cut.wav'"]},{"cell_type":"code","execution_count":null,"id":"em2KTwlXsAOQ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":1251,"status":"ok","timestamp":1704837472581,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"em2KTwlXsAOQ","outputId":"89712d29-b195-4230-c15b-48be3d762313"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-fc5842bc-88ce-4be8-a377-321a3d85f664\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>data/train/第10課-2-字幕版.0._cut.wav</td>\n","      <td>大家看那個章天亮教授那個笑談風雲裏面</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>data/train/第10課-2-字幕版.1._cut.wav</td>\n","      <td>他前面講了這個三場大風造成改變了中國的歷史</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>data/train/第10課-2-字幕版.2._cut.wav</td>\n","      <td>這都是真實的事情</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>data/train/第10課-2-字幕版.3._cut.wav</td>\n","      <td>那我再補充一個</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>data/train/第10課-2-字幕版.4._cut.wav</td>\n","      <td>當時就是明太祖跟陳友諒大戰的時候</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21350</th>\n","      <td>data/test/CLC015-3-字幕版.565._cut.wav</td>\n","      <td>就是寫史書</td>\n","    </tr>\n","    <tr>\n","      <th>21351</th>\n","      <td>data/test/CLC015-3-字幕版.566._cut.wav</td>\n","      <td>學生史書啊</td>\n","    </tr>\n","    <tr>\n","      <th>21352</th>\n","      <td>data/test/CLC015-3-字幕版.567._cut.wav</td>\n","      <td>對你用白話文把我給你的這些材料寫成通順的文章</td>\n","    </tr>\n","    <tr>\n","      <th>21353</th>\n","      <td>data/test/CLC015-3-字幕版.568._cut.wav</td>\n","      <td>就是介紹這一朝講這一朝歷史</td>\n","    </tr>\n","    <tr>\n","      <th>21354</th>\n","      <td>data/test/CLC015-3-字幕版.569._cut.wav</td>\n","      <td>講這一部分的歷史</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21355 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc5842bc-88ce-4be8-a377-321a3d85f664')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fc5842bc-88ce-4be8-a377-321a3d85f664 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fc5842bc-88ce-4be8-a377-321a3d85f664');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a7f351ba-022a-4967-9f1c-59a6563afdd5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7f351ba-022a-4967-9f1c-59a6563afdd5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a7f351ba-022a-4967-9f1c-59a6563afdd5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_a083f43e-f43b-4a0f-ac6c-8aec4007a075\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metadata_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_a083f43e-f43b-4a0f-ac6c-8aec4007a075 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('metadata_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                 file_name                sentence\n","0         data/train/第10課-2-字幕版.0._cut.wav      大家看那個章天亮教授那個笑談風雲裏面\n","1         data/train/第10課-2-字幕版.1._cut.wav   他前面講了這個三場大風造成改變了中國的歷史\n","2         data/train/第10課-2-字幕版.2._cut.wav                這都是真實的事情\n","3         data/train/第10課-2-字幕版.3._cut.wav                 那我再補充一個\n","4         data/train/第10課-2-字幕版.4._cut.wav        當時就是明太祖跟陳友諒大戰的時候\n","...                                    ...                     ...\n","21350  data/test/CLC015-3-字幕版.565._cut.wav                   就是寫史書\n","21351  data/test/CLC015-3-字幕版.566._cut.wav                   學生史書啊\n","21352  data/test/CLC015-3-字幕版.567._cut.wav  對你用白話文把我給你的這些材料寫成通順的文章\n","21353  data/test/CLC015-3-字幕版.568._cut.wav           就是介紹這一朝講這一朝歷史\n","21354  data/test/CLC015-3-字幕版.569._cut.wav                講這一部分的歷史\n","\n","[21355 rows x 2 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["metadata_df = pd.DataFrame()\n","metadata_df['file_name'] = all_subtitles_audio\n","metadata_df['sentence'] = all_subtitles_text\n","\n","metadata_df.to_csv(f\"{train_test_split_folder}/metadata.csv\", index = False)\n","metadata_df"]},{"cell_type":"code","execution_count":null,"id":"R88mfcfcAKoc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1704749794899,"user":{"displayName":"Ian Liu","userId":"10053214275715814514"},"user_tz":300},"id":"R88mfcfcAKoc","outputId":"b939dcb7-664e-462d-9c64-27a7e8bc718e"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'transcription'],\n","        num_rows: 0\n","    })\n","    test: Dataset({\n","        features: ['audio', 'transcription'],\n","        num_rows: 0\n","    })\n","})"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["full_dataset"]},{"cell_type":"code","execution_count":null,"id":"jCsQG-Sqp48Z","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["64e21a670d35479a81dc92bbf8f93b88","2aed076bc34c482d8a3396c3db6de3f5","266833fe4be94f49802e763aa4fc36f4","82abefcca1cb420eb35ed80b39784f41","d81db4c8bc5c4d998e5d20484bfd6bbc","88e0a60b35a546349947ce38c5763f43","d1e8e77f22574140b9e41f16b0a3096c","18fb772442d54ba583fcbd6ed8b9b594","1737538c71be423c9d5e51fecbff32bc","bdc5c40fb9a743e3b8119cd1016ef360","f7ecaaa1632b4bd083baf5c8079abcda","542130c0cbdd478286bde682ddd150ac","a60c757a35ee4733b62827ca5663d274","c3e296ca2e94465cb75177cadeb23000","42bf54e80041474185cebb0c82a60e14","7be27541d2d84f35be56254d89c537fe","b0be5ccd757d45e697926215509e4b37","dcb012679bc444c4a9cda5c16201b0bd","ee6312bfc515403f8f3a1c00d7cfff13","a5425af01d834bdaad3e3b43ca2c2e57","112c5a8d73464eb9932624c9a038a9a2","3093508b13514c109a177e4df5563d25"]},"executionInfo":{"elapsed":162167,"status":"ok","timestamp":1704857636202,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"jCsQG-Sqp48Z","outputId":"652e92fd-7d9d-43bc-f391-1e2a8ddb0042"},"outputs":[],"source":["from datasets import load_dataset, DatasetDict\n","\n","entire_dataset = load_dataset(\"audiofolder\", data_dir=train_test_split_folder)"]},{"cell_type":"code","execution_count":null,"id":"0xr4AopAnRnx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1704853507901,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"0xr4AopAnRnx","outputId":"1a9a3293-64a8-4fba-c8df-e1ef8294eeaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 18395\n","    })\n","    test: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 2960\n","    })\n","})\n"]}],"source":["print(entire_dataset)"]},{"cell_type":"code","execution_count":null,"id":"kb3tE0UbnTpo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1704853507901,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"kb3tE0UbnTpo","outputId":"e9166f5b-a766-473d-e8e4-4d30cc92b3c7"},"outputs":[{"data":{"text/plain":["datasets.dataset_dict.DatasetDict"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["type(entire_dataset)"]},{"cell_type":"code","execution_count":null,"id":"O78o3bvZnluo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1704853507901,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"O78o3bvZnluo","outputId":"3b634872-a1c2-4910-84f5-c5c4fb85f750"},"outputs":[{"data":{"text/plain":["dict_keys(['train', 'test'])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["entire_dataset.keys()"]},{"cell_type":"code","execution_count":null,"id":"4MjvXQjKMgyE","metadata":{"id":"4MjvXQjKMgyE"},"outputs":[],"source":["type(entire_dataset['train'])"]},{"cell_type":"code","execution_count":null,"id":"Wad50bobITgv","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"elapsed":182,"status":"error","timestamp":1704758217307,"user":{"displayName":"Ian Liu","userId":"10053214275715814514"},"user_tz":300},"id":"Wad50bobITgv","outputId":"bbca8020-c279-497c-dfc9-20c67449be39"},"outputs":[],"source":["print(entire_dataset[\"train\"]['train'][0])"]},{"cell_type":"code","execution_count":null,"id":"F-YKKNwaGq3t","metadata":{"id":"F-YKKNwaGq3t"},"outputs":[],"source":["test_dataset"]},{"cell_type":"markdown","id":"2d63b2d2-f68a-4d74-b7f1-5127f6d16605","metadata":{"id":"2d63b2d2-f68a-4d74-b7f1-5127f6d16605"},"source":["## Prepare Feature Extractor, Tokenizer and Data"]},{"cell_type":"code","execution_count":7,"id":"bc77d7bb-f9e2-47f5-b663-30f7a4321ce5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1193,"status":"ok","timestamp":1704857163367,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"bc77d7bb-f9e2-47f5-b663-30f7a4321ce5","outputId":"d8e86f46-0d50-45f5-e888-c744361e408a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["from transformers import WhisperFeatureExtractor\n","\n","feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)"]},{"cell_type":"code","execution_count":8,"id":"c7b07f9b-ae0e-4f89-98f0-0c50d432eab6","metadata":{"executionInfo":{"elapsed":834,"status":"ok","timestamp":1704857164827,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"c7b07f9b-ae0e-4f89-98f0-0c50d432eab6"},"outputs":[],"source":["from transformers import WhisperTokenizer\n","\n","tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)"]},{"cell_type":"code","execution_count":9,"id":"77d9f0c5-8607-4642-a8ac-c3ab2e223ea6","metadata":{"executionInfo":{"elapsed":202,"status":"ok","timestamp":1704857166031,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"77d9f0c5-8607-4642-a8ac-c3ab2e223ea6"},"outputs":[],"source":["from transformers import WhisperProcessor\n","\n","processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)"]},{"cell_type":"markdown","id":"381acd09-0b0f-4d04-9eb3-f028ac0e5f2c","metadata":{"id":"381acd09-0b0f-4d04-9eb3-f028ac0e5f2c"},"source":["### Prepare Data"]},{"cell_type":"markdown","id":"5a679f05-063d-41b3-9b58-4fc9c6ccf4fd","metadata":{"id":"5a679f05-063d-41b3-9b58-4fc9c6ccf4fd"},"source":["Since\n","our input audio is sampled at 48kHz, we need to _downsample_ it to\n","16kHz prior to passing it to the Whisper feature extractor, 16kHz being the sampling rate expected by the Whisper model.\n","\n","We'll set the audio inputs to the correct sampling rate using dataset's\n","[`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column)\n","method. This operation does not change the audio in-place,\n","but rather signals to `datasets` to resample audio samples _on the fly_ the\n","first time that they are loaded:"]},{"cell_type":"code","execution_count":12,"id":"7sfEHa1OJpE2","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1704857636203,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"7sfEHa1OJpE2"},"outputs":[],"source":["from datasets import Audio\n","\n","entire_dataset = entire_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"]},{"cell_type":"markdown","id":"00382a3e-abec-4cdd-a54c-d1aaa3ea4707","metadata":{"id":"00382a3e-abec-4cdd-a54c-d1aaa3ea4707"},"source":["Re-loading the first audio sample in the Common Voice dataset will resample\n","it to the desired sampling rate:"]},{"cell_type":"code","execution_count":null,"id":"Ee96CXd69Yuh","metadata":{"id":"Ee96CXd69Yuh"},"outputs":[],"source":["import pickle\n","\n","with open('entire_dataset.pkl', 'wb') as f:\n","    pickle.dump(entire_dataset, f)"]},{"cell_type":"code","execution_count":null,"id":"yvMS10oTl-RX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1415,"status":"ok","timestamp":1704849663662,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"yvMS10oTl-RX","outputId":"b3531e1c-0a18-47c0-f2ad-9e67d0ef7845"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'audio': {'path': '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/train/第10課-1-字幕版.0._cut.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.11165189,\n","       -0.07839113, -0.02468587]), 'sampling_rate': 16000}, 'sentence': '這節課我們結束了第一個單元'}\n"]}],"source":["print(entire_dataset[\"train\"][0])"]},{"cell_type":"markdown","id":"91edc72d-08f8-4f01-899d-74e65ce441fc","metadata":{"id":"91edc72d-08f8-4f01-899d-74e65ce441fc"},"source":["Now we can write a function to prepare our data ready for the model:\n","1. We load and resample the audio data by calling `batch[\"audio\"]`. As explained above, 🤗 Datasets performs any necessary resampling operations on the fly.\n","2. We use the feature extractor to compute the log-Mel spectrogram input features from our 1-dimensional audio array.\n","3. We encode the transcriptions to label ids through the use of the tokenizer."]},{"cell_type":"code","execution_count":13,"id":"6525c478-8962-4394-a1c4-103c54cce170","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1704857636203,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"6525c478-8962-4394-a1c4-103c54cce170"},"outputs":[],"source":["def prepare_dataset(batch):\n","    # load and resample audio data from 48 to 16kHz\n","    audio = batch[\"audio\"]\n","\n","    # compute log-Mel input features from input audio array\n","    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","\n","    # encode target text to label ids\n","    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n","    return batch"]},{"cell_type":"markdown","id":"70b319fb-2439-4ef6-a70d-a47bf41c4a13","metadata":{"id":"70b319fb-2439-4ef6-a70d-a47bf41c4a13"},"source":["We can apply the data preparation function to all of our training examples using dataset's `.map` method. The argument `num_proc` specifies how many CPU cores to use. Setting `num_proc` > 1 will enable multiprocessing. If the `.map` method hangs with multiprocessing, set `num_proc=1` and process the dataset sequentially."]},{"cell_type":"code","execution_count":null,"id":"sS6o5JOszQFD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211,"status":"ok","timestamp":1704830252459,"user":{"displayName":"Ian Liu","userId":"10053214275715814514"},"user_tz":300},"id":"sS6o5JOszQFD","outputId":"2f0b7791-d0ec-4da2-bfc5-a8555939f5c8"},"outputs":[{"data":{"text/plain":["{'audio': {'path': '/content/drive/Shareddrives/FTCM/CIS335 ML&AI/Group Bonus Project/Part 2/WAV_train_test_split/data/train/第10課-1-字幕版.128._cut.wav',\n","  'array': array([-0.00620656, -0.00869003, -0.00709007, ..., -0.08543612,\n","         -0.05781476, -0.02823488]),\n","  'sampling_rate': 16000},\n"," 'sentence': '然後不是一個'}"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["entire_dataset['train'][33]"]},{"cell_type":"code","execution_count":null,"id":"y6W06daWK3L_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1704853512734,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"y6W06daWK3L_","outputId":"ef2a1f46-fc1f-4a39-e628-ccb2da882e51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Architecture:            x86_64\n","  CPU op-mode(s):        32-bit, 64-bit\n","  Address sizes:         46 bits physical, 48 bits virtual\n","  Byte Order:            Little Endian\n","CPU(s):                  8\n","  On-line CPU(s) list:   0-7\n","Vendor ID:               GenuineIntel\n","  Model name:            Intel(R) Xeon(R) CPU @ 2.00GHz\n","    CPU family:          6\n","    Model:               85\n","    Thread(s) per core:  2\n","    Core(s) per socket:  4\n","    Socket(s):           1\n","    Stepping:            3\n","    BogoMIPS:            4000.28\n","    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n","                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_\n","                         good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fm\n","                         a cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hyp\n","                         ervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsb\n","                         ase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512d\n","                         q rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsave\n","                         c xgetbv1 xsaves arat md_clear arch_capabilities\n","Virtualization features: \n","  Hypervisor vendor:     KVM\n","  Virtualization type:   full\n","Caches (sum of all):     \n","  L1d:                   128 KiB (4 instances)\n","  L1i:                   128 KiB (4 instances)\n","  L2:                    4 MiB (4 instances)\n","  L3:                    38.5 MiB (1 instance)\n","NUMA:                    \n","  NUMA node(s):          1\n","  NUMA node0 CPU(s):     0-7\n","Vulnerabilities:         \n","  Gather data sampling:  Not affected\n","  Itlb multihit:         Not affected\n","  L1tf:                  Mitigation; PTE Inversion\n","  Mds:                   Vulnerable; SMT Host state unknown\n","  Meltdown:              Vulnerable\n","  Mmio stale data:       Vulnerable\n","  Retbleed:              Vulnerable\n","  Spec rstack overflow:  Not affected\n","  Spec store bypass:     Vulnerable\n","  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy barriers only; no swap\n","                         gs barriers\n","  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBRS: Not affected\n","  Srbds:                 Not affected\n","  Tsx async abort:       Vulnerable\n"]}],"source":["!lscpu"]},{"cell_type":"code","execution_count":14,"id":"SMb3r3_pJ245","metadata":{"executionInfo":{"elapsed":9641,"status":"ok","timestamp":1704857645843,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"SMb3r3_pJ245"},"outputs":[],"source":["entire_dataset = entire_dataset.map(prepare_dataset,\n","                                    num_proc=8)"]},{"cell_type":"code","execution_count":null,"id":"c4be572c","metadata":{"id":"c4be572c"},"outputs":[],"source":["common_voice[\"train\"]"]},{"cell_type":"code","execution_count":null,"id":"XFaBGVvqJ6x7","metadata":{"id":"XFaBGVvqJ6x7"},"outputs":[],"source":["entire_dataset[\"train\"]"]},{"cell_type":"markdown","id":"263a5a58-0239-4a25-b0df-c625fc9c5810","metadata":{"id":"263a5a58-0239-4a25-b0df-c625fc9c5810"},"source":["## Training and Evaluation"]},{"cell_type":"markdown","id":"8d230e6d-624c-400a-bbf5-fa660881df25","metadata":{"id":"8d230e6d-624c-400a-bbf5-fa660881df25"},"source":["### Define a Data Collator"]},{"cell_type":"code","execution_count":15,"id":"8326221e-ec13-4731-bb4e-51e5fc1486c5","metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1704857645844,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"8326221e-ec13-4731-bb4e-51e5fc1486c5"},"outputs":[],"source":["import torch\n","\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lengths and need different padding methods\n","        # first treat the audio inputs by simply returning torch tensors\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","        # get the tokenized label sequences\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        # pad the labels to max length\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        # if bos token is appended in previous tokenization step,\n","        # cut bos token here as it's append later anyways\n","        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"]},{"cell_type":"markdown","id":"3cae7dbf-8a50-456e-a3a8-7fd005390f86","metadata":{"id":"3cae7dbf-8a50-456e-a3a8-7fd005390f86"},"source":["Let's initialise the data collator we've just defined:"]},{"cell_type":"code","execution_count":16,"id":"fc834702-c0d3-4a96-b101-7b87be32bf42","metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1704857645844,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"fc834702-c0d3-4a96-b101-7b87be32bf42"},"outputs":[],"source":["data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"]},{"cell_type":"markdown","id":"d62bb2ab-750a-45e7-82e9-61d6f4805698","metadata":{"id":"d62bb2ab-750a-45e7-82e9-61d6f4805698"},"source":["### Evaluation Metrics"]},{"cell_type":"markdown","id":"66fee1a7-a44c-461e-b047-c3917221572e","metadata":{"id":"66fee1a7-a44c-461e-b047-c3917221572e"},"source":["We'll use the word error rate (WER) metric, the 'de-facto' metric for assessing\n","ASR systems. For more information, refer to the WER [docs](https://huggingface.co/metrics/wer). We'll load the WER metric from 🤗 Evaluate:"]},{"cell_type":"code","execution_count":17,"id":"b22b4011-f31f-4b57-b684-c52332f92890","metadata":{"executionInfo":{"elapsed":1200,"status":"ok","timestamp":1704857647044,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"b22b4011-f31f-4b57-b684-c52332f92890"},"outputs":[],"source":["import evaluate\n","\n","metric = evaluate.load(\"wer\")"]},{"cell_type":"markdown","id":"4f32cab6-31f0-4cb9-af4c-40ba0f5fc508","metadata":{"id":"4f32cab6-31f0-4cb9-af4c-40ba0f5fc508"},"source":["We then simply have to define a function that takes our model\n","predictions and returns the WER metric. This function, called\n","`compute_metrics`, first replaces `-100` with the `pad_token_id`\n","in the `label_ids` (undoing the step we applied in the\n","data collator to ignore padded tokens correctly in the loss).\n","It then decodes the predicted and label ids to strings. Finally,\n","it computes the WER between the predictions and reference labels:"]},{"cell_type":"code","execution_count":18,"id":"23959a70-22d0-4ffe-9fa1-72b61e75bb52","metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1704857647045,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"23959a70-22d0-4ffe-9fa1-72b61e75bb52"},"outputs":[],"source":["def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"]},{"cell_type":"markdown","id":"daf2a825-6d9f-4a23-b145-c37c0039075b","metadata":{"id":"daf2a825-6d9f-4a23-b145-c37c0039075b"},"source":["### Load a Pre-Trained Checkpoint"]},{"cell_type":"markdown","id":"437a97fa-4864-476b-8abc-f28b8166cfa5","metadata":{"id":"437a97fa-4864-476b-8abc-f28b8166cfa5"},"source":["Now let's load the pre-trained Whisper `small` checkpoint. Again, this\n","is trivial through use of 🤗 Transformers!"]},{"cell_type":"code","execution_count":19,"id":"5a10cc4b-07ec-4ebd-ac1d-7c601023594f","metadata":{"executionInfo":{"elapsed":6415,"status":"ok","timestamp":1704857653460,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"5a10cc4b-07ec-4ebd-ac1d-7c601023594f"},"outputs":[],"source":["from transformers import WhisperForConditionalGeneration\n","\n","model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n","\n","# model.hf_device_map - this should be {\" \": 0}"]},{"cell_type":"markdown","id":"a15ead5f-2277-4a39-937b-585c2497b2df","metadata":{"id":"a15ead5f-2277-4a39-937b-585c2497b2df"},"source":["Override generation arguments - no tokens are forced as decoder outputs (see [`forced_decoder_ids`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids)), no tokens are suppressed during generation (see [`suppress_tokens`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens)):"]},{"cell_type":"code","execution_count":null,"id":"62038ba3-88ed-4fce-84db-338f50dcd04f","metadata":{"id":"62038ba3-88ed-4fce-84db-338f50dcd04f"},"outputs":[],"source":["model.config.forced_decoder_ids = None\n","model.config.suppress_tokens = []"]},{"cell_type":"markdown","id":"bR-_yaEOPsfQ","metadata":{"id":"bR-_yaEOPsfQ"},"source":["### Post-processing on the model\n","\n","Finally, we need to apply some post-processing on the 8-bit model to enable training, let's freeze all our layers, and cast the layer-norm in `float32` for stability. We also cast the output of the last layer in `float32` for the same reasons."]},{"cell_type":"code","execution_count":21,"id":"Cl_ZQualPt9R","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704857653463,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"Cl_ZQualPt9R","outputId":"c4bdcfc4-96af-4590-f3c8-d7f88361cf6c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:145: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]}],"source":["from peft import prepare_model_for_int8_training\n","\n","model = prepare_model_for_int8_training(model)\n","# model = prepare_model_for_training(model, output_embedding_layer_name=\"proj_out\")"]},{"cell_type":"markdown","id":"Vjl4j4RJPmPR","metadata":{"id":"Vjl4j4RJPmPR"},"source":["### Apply LoRA\n","\n","Here comes the magic with `peft`! Let's load a `PeftModel` and specify that we are going to use low-rank adapters (LoRA) using `get_peft_model` utility function from `peft`."]},{"cell_type":"code","execution_count":22,"id":"DQtpDPRHPyOL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1121,"status":"ok","timestamp":1704857654584,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"DQtpDPRHPyOL","outputId":"155976e8-d818-4927-cbcb-bfe27581f422"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 15,728,640 || all params: 1,559,033,600 || trainable%: 1.0088711365810203\n"]}],"source":["from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n","\n","config = LoraConfig(r=32, lora_alpha=64, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\")\n","\n","model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"markdown","id":"3906d436","metadata":{"id":"3906d436"},"source":["We are ONLY using **1%** of the total trainable parameters, thereby performing **Parameter-Efficient Fine-Tuning**"]},{"cell_type":"markdown","id":"2178dea4-80ca-47b6-b6ea-ba1915c90c06","metadata":{"id":"2178dea4-80ca-47b6-b6ea-ba1915c90c06"},"source":["### Define the Training Configuration"]},{"cell_type":"markdown","id":"c21af1e9-0188-4134-ac82-defc7bdcc436","metadata":{"id":"c21af1e9-0188-4134-ac82-defc7bdcc436"},"source":["In the final step, we define all the parameters related to training. For more detail on the training arguments, refer to the Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)."]},{"cell_type":"code","execution_count":35,"id":"0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a","metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1704858758291,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"},"outputs":[],"source":["from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"temp\",  # change to a repo name of your choice\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n","    learning_rate=1e-3,\n","    warmup_steps=50,\n","    num_train_epochs=3,\n","    evaluation_strategy=\"epoch\",\n","    fp16=True,\n","    per_device_eval_batch_size=4,\n","    generation_max_length=128,\n","    logging_steps=25,\n","    remove_unused_columns=False,  # required as the PeftModel forward doesn't have the signature of the wrapped model's forward\n","    label_names=[\"labels\"],  # same reason as above\n",")"]},{"cell_type":"markdown","id":"b3a944d8-3112-4552-82a0-be25988b3857","metadata":{"id":"b3a944d8-3112-4552-82a0-be25988b3857"},"source":["**Few Important Notes:**\n","1. `remove_unused_columns=False` and `label_names=[\"labels\"]` are required as the PeftModel's forward doesn't have the signature of the base model's forward.\n","\n","2. INT8 training required autocasting. `predict_with_generate` can't be passed to Trainer because it internally calls transformer's `generate` without autocasting leading to errors.\n","\n","3. Because of point 2, `compute_metrics` shouldn't be passed to `Seq2SeqTrainer` as seen below. (commented out)"]},{"cell_type":"code","execution_count":36,"id":"wkC5E3heJe74","metadata":{"executionInfo":{"elapsed":604,"status":"ok","timestamp":1704858762324,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"wkC5E3heJe74"},"outputs":[],"source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=entire_dataset[\"train\"],\n","    eval_dataset=entire_dataset[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=processor.feature_extractor,\n",")\n","model.config.use_cache = True  # silence the warnings. Please re-enable for inference!"]},{"cell_type":"markdown","id":"V842MDEDmYl-","metadata":{"id":"V842MDEDmYl-"},"source":["Before training"]},{"cell_type":"code","execution_count":null,"id":"p7tcj7dceUsl","metadata":{"id":"p7tcj7dceUsl"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":28,"id":"9qh_lDTRHAMZ","metadata":{"executionInfo":{"elapsed":611,"status":"ok","timestamp":1704858303759,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"9qh_lDTRHAMZ"},"outputs":[],"source":["model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"]},{"cell_type":"code","execution_count":38,"id":"zm1RqKG67n5_","metadata":{"executionInfo":{"elapsed":1401,"status":"ok","timestamp":1704858863814,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"zm1RqKG67n5_"},"outputs":[],"source":["import torch\n","from numba import cuda\n","device = cuda.get_current_device()\n","device.reset()\n","# torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"ee8b7b8e-1c9a-4d77-9137-1778a629e6de","metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1704856827220,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"ee8b7b8e-1c9a-4d77-9137-1778a629e6de"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"0576aa2a","metadata":{"id":"0576aa2a"},"outputs":[],"source":["model_name_or_path = \"openai/whisper-large-v2\"\n","peft_model_id = \"smangrul/\" + f\"{model_name_or_path}-{model.peft_config.peft_type}-colab\".replace(\"/\", \"-\")\n","model.push_to_hub(peft_model_id)\n","print(peft_model_id)"]},{"cell_type":"markdown","id":"SlyyOGnPgi_I","metadata":{"id":"SlyyOGnPgi_I"},"source":["# Evaluation and Inference"]},{"cell_type":"markdown","id":"Kzfg2qoXgrhg","metadata":{"id":"Kzfg2qoXgrhg"},"source":["**Important points to note while inferencing**:\n","1. As `predict_with_generate` can't be used, we will write the eval loop with `torch.cuda.amp.autocast()` as shown below.\n","2. As the base model is frozen, PEFT model sometimes fails ot recognise the language while decoding.Hence, we force the starting tokens to mention the language we are transcribing. This is done via `forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"Marathi\", task=\"transcribe\")` and passing that too the `model.generate` call.\n","3. Please note that [AutoEvaluate Leaderboard](https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=mozilla-foundation%2Fcommon_voice_11_0&only_verified=0&task=automatic-speech-recognition&config=mr&split=test&metric=wer) for `mr` language on `common_voice_11_0` has a bug wherein openai's `BasicTextNormalizer` normalizer is used while evaluation leading to degerated output text, an example is shown below:\n","```\n","without normalizer: 'स्विच्चान नरुवित्तीची पद्दत मोठ्या प्रमाणात आमलात आणल्या बसोन या दुपन्याने अनेक राथ प्रवेश केला आहे.'\n","with normalizer: 'स व च च न नर व त त च पद दत म ठ य प रम ण त आमल त आणल य बस न य द पन य न अन क र थ प रव श क ल आह'\n","```\n","Post fixing this bug, we report the 2 metrics for the top model of the leaderboard and the PEFT model:\n","1. `wer`: `wer` without using the `BasicTextNormalizer` as it doesn't cater to most indic languages. This is want we consider as true performance metric.\n","2. `normalized_wer`: `wer` using the `BasicTextNormalizer` to be comparable to the leaderboard metrics.\n","Below are the results:\n","\n","| Model          | DrishtiSharma/whisper-large-v2-marathi | smangrul/openai-whisper-large-v2-LORA-colab |\n","|----------------|----------------------------------------|---------------------------------------------|\n","| wer            | 35.6457                                | 36.1356                                     |\n","| normalized_wer | 13.6440                                | 14.0165                                     |\n","\n","We see that PEFT model's performance is comparable to the fully fine-tuned model on the top of the leaderboard. At the same time, we are able to train the large model in Colab notebook with limited GPU memory and the added advantage of resulting checkpoint being jsut `63` MB.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"273a996c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":562,"status":"error","timestamp":1704858290327,"user":{"displayName":"Ian Liu","userId":"17609049576601953865"},"user_tz":300},"id":"273a996c","outputId":"5b3681be-059e-48c7-fdf1-d6bbe8d098da"},"outputs":[],"source":["from peft import PeftModel, PeftConfig\n","from transformers import WhisperForConditionalGeneration, Seq2SeqTrainer\n","\n","peft_model_id = \"smangrul/openai-whisper-large-v2-LORA-colab\"\n","peft_config = PeftConfig.from_pretrained(peft_model_id)\n","model = WhisperForConditionalGeneration.from_pretrained(\n","    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",")\n","model = PeftModel.from_pretrained(model, peft_model_id)"]},{"cell_type":"code","execution_count":null,"id":"401ceaa6","metadata":{"id":"401ceaa6"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import numpy as np\n","import gc\n","\n","eval_dataloader = DataLoader(common_voice[\"test\"], batch_size=8, collate_fn=data_collator)\n","\n","model.eval()\n","for step, batch in enumerate(tqdm(eval_dataloader)):\n","    with torch.cuda.amp.autocast():\n","        with torch.no_grad():\n","            generated_tokens = (\n","                model.generate(\n","                    input_features=batch[\"input_features\"].to(\"cuda\"),\n","                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),\n","                    max_new_tokens=255,\n","                )\n","                .cpu()\n","                .numpy()\n","            )\n","            labels = batch[\"labels\"].cpu().numpy()\n","            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","            metric.add_batch(\n","                predictions=decoded_preds,\n","                references=decoded_labels,\n","            )\n","    del generated_tokens, labels, batch\n","    gc.collect()\n","wer = 100 * metric.compute()\n","print(f\"{wer=}\")"]},{"cell_type":"markdown","id":"8ZN4pTangw98","metadata":{"id":"8ZN4pTangw98"},"source":["## Using AutomaticSpeechRecognitionPipeline"]},{"cell_type":"markdown","id":"hpDx1AOCgwuk","metadata":{"id":"hpDx1AOCgwuk"},"source":["**Few important notes:**\n","1. `pipe()` should be in the autocast context manager `with torch.cuda.amp.autocast():`\n","2. `forced_decoder_ids` specifying the `language` being transcribed should be provided in `generate_kwargs` dict.\n","3. You will get warning along the below lines which is **safe to ignore**.\n","```\n","The model 'PeftModel' is not supported for . Supported models are ['SpeechEncoderDecoderModel', 'Speech2TextForConditionalGeneration', 'SpeechT5ForSpeechToText', 'WhisperForConditionalGeneration', 'Data2VecAudioForCTC', 'HubertForCTC', 'MCTCTForCTC', 'SEWForCTC', 'SEWDForCTC', 'UniSpeechForCTC', 'UniSpeechSatForCTC', 'Wav2Vec2ForCTC', 'Wav2Vec2ConformerForCTC', 'WavLMForCTC'].\n","\n","```"]},{"cell_type":"code","execution_count":null,"id":"fa2b62a3","metadata":{"id":"fa2b62a3"},"outputs":[],"source":["import torch\n","import gradio as gr\n","from transformers import (\n","    AutomaticSpeechRecognitionPipeline,\n","    WhisperForConditionalGeneration,\n","    WhisperTokenizer,\n","    WhisperProcessor,\n",")\n","from peft import PeftModel, PeftConfig\n","\n","\n","peft_model_id = \"smangrul/openai-whisper-large-v2-LORA-colab\"\n","language = \"Chinese\"\n","task = \"transcribe\"\n","peft_config = PeftConfig.from_pretrained(peft_model_id)\n","model = WhisperForConditionalGeneration.from_pretrained(\n","    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",")\n","\n","model = PeftModel.from_pretrained(model, peft_model_id)\n","tokenizer = WhisperTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n","processor = WhisperProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n","feature_extractor = processor.feature_extractor\n","forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n","pipe = AutomaticSpeechRecognitionPipeline(model=model, tokenizer=tokenizer, feature_extractor=feature_extractor)\n","\n","\n","def transcribe(audio):\n","    with torch.cuda.amp.autocast():\n","        text = pipe(audio, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids}, max_new_tokens=255)[\"text\"]\n","    return text\n","\n","\n","iface = gr.Interface(\n","    fn=transcribe,\n","    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n","    outputs=\"text\",\n","    title=\"PEFT LoRA + INT8 Whisper Large V2 Marathi\",\n","    description=\"Realtime demo for Marathi speech recognition using `PEFT-LoRA+INT8` fine-tuned Whisper Large V2 model.\",\n",")\n","\n","iface.launch(share=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["awt7ltO2mnar"],"gpuType":"V100","machine_shape":"hm","provenance":[{"file_id":"1tDygMsXzGslFgSqAR-qGUh99tuGTXhPC","timestamp":1704331238287},{"file_id":"1DOkD_5OUjFa0r5Ik3SgywJLJtEo2qLxO","timestamp":1699994178303}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"081642fe533746a2b5e9966e1b81280a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089eb6a360d3461e96d696c686b29b05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_cf5a1711cdb34cbd9905a7c615d0c44f","IPY_MODEL_9f079f19acaf44fabba70c32f146776a","IPY_MODEL_bc6c07e90a824852871314c2edde98d5","IPY_MODEL_f46b38f981644b4ea29c20c5c6fcf587"],"layout":"IPY_MODEL_f79021fd9e8c40d99bb10c3fe025f4ba"}},"112c5a8d73464eb9932624c9a038a9a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"121cf9cbc169466b94490d731dd39dbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16ea7f216bf54659aa36cc10391b297c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5377555f58d47b7b5d817ab6acdcb5e","IPY_MODEL_866405fbab3f4c3d8dbdd8cfeb56c2a8","IPY_MODEL_71bced7f7b7b4364a582d83504568c73"],"layout":"IPY_MODEL_a862a0a40dd14543a89616d43fdc6963"}},"1737538c71be423c9d5e51fecbff32bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"187f57f867764d6790604cf6b2f3b58f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18fb772442d54ba583fcbd6ed8b9b594":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"191f5b03a2f34b7fb81b37c995eebafb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"195344ba0fc646a6b995d3f7008d9374":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1df7fe6d54944d28ae6a34a256ecef24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_990abad8b2ab448bb531af1189c17b93","IPY_MODEL_e9775d8127bf4f15bccaaa5755748c55","IPY_MODEL_9ca2f786074d4aef94fd75eea7bd93bd"],"layout":"IPY_MODEL_72947257ead14d3e88ff7009863248d8"}},"1ee04e2a9c40405ab4b644c3a0d91e32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"266833fe4be94f49802e763aa4fc36f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18fb772442d54ba583fcbd6ed8b9b594","max":18395,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1737538c71be423c9d5e51fecbff32bc","value":18395}},"2718ed0370cd497a8a55ed90e87865fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"278a72b8f46441149fbc04dd7dfe9eaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_5284cbf6f5344dc9a059e66009da2c8d","style":"IPY_MODEL_2718ed0370cd497a8a55ed90e87865fe","value":true}},"282bf68f745d4d5890889a5e011b9c22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a30f66860354787b938f061b71607e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"2a5cb1b700294e59b2424b577e686f4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aed076bc34c482d8a3396c3db6de3f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88e0a60b35a546349947ce38c5763f43","placeholder":"​","style":"IPY_MODEL_d1e8e77f22574140b9e41f16b0a3096c","value":"Resolving data files: 100%"}},"3093508b13514c109a177e4df5563d25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36b8688ee1a54b3aa161f0b8388ba225":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d48c12fabf024a9faeb0e255a409703a","placeholder":"​","style":"IPY_MODEL_282bf68f745d4d5890889a5e011b9c22","value":" 2961/2961 [00:00&lt;00:00, 5407.45it/s]"}},"36d661f3674f4a418904aead3148a9d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38efbda33170462988008da40974bb38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9ed46b759e24d1b8d16e03ed6873e77","placeholder":"​","style":"IPY_MODEL_fa6fb1445752440487816a1ebd3398a6","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"392fe36405274793ae4e4b803bf12930":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d133e8bf07641e1aeac089ab2cf4313":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f630911735946f0854eee7777340c1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42bf54e80041474185cebb0c82a60e14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_112c5a8d73464eb9932624c9a038a9a2","placeholder":"​","style":"IPY_MODEL_3093508b13514c109a177e4df5563d25","value":" 2960/2960 [00:00&lt;00:00, 53871.36it/s]"}},"437e2e325d544583815863c57bda5e62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48f58bc396a54264beae8b6a0c4c08cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4af9d1a937f746948e3f915e06c5ad11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57f63b66ff414448b607abdf63b680fc","placeholder":"​","style":"IPY_MODEL_48f58bc396a54264beae8b6a0c4c08cb","value":"Resolving data files: 100%"}},"5284cbf6f5344dc9a059e66009da2c8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"542130c0cbdd478286bde682ddd150ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a60c757a35ee4733b62827ca5663d274","IPY_MODEL_c3e296ca2e94465cb75177cadeb23000","IPY_MODEL_42bf54e80041474185cebb0c82a60e14"],"layout":"IPY_MODEL_7be27541d2d84f35be56254d89c537fe"}},"5725dfe3994c489ca94fefb0cd058afb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d19a0d3374433fbaa9a4864a5dc785":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57f63b66ff414448b607abdf63b680fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fab8669bb1141089b5d9a92a2985820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90df9cac606a4888afaa01b609b1c9a7","max":2961,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb8b42bd68404979bf76f124e6c99f1e","value":2961}},"62f1cd7e72fc4cfbbd199e0c07c7df47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3771b128d314796bbd2185ce8a6bc8c","placeholder":"​","style":"IPY_MODEL_191f5b03a2f34b7fb81b37c995eebafb","value":"Map: 100%"}},"64e21a670d35479a81dc92bbf8f93b88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2aed076bc34c482d8a3396c3db6de3f5","IPY_MODEL_266833fe4be94f49802e763aa4fc36f4","IPY_MODEL_82abefcca1cb420eb35ed80b39784f41"],"layout":"IPY_MODEL_d81db4c8bc5c4d998e5d20484bfd6bbc"}},"6ff999d7df8c47cf88466896c19b4bae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0a1b30cf6fc4fca86b5924a396f7bea","max":11277,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0b51deca5394b09bc9493a0af5dad99","value":11277}},"71bced7f7b7b4364a582d83504568c73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36d661f3674f4a418904aead3148a9d9","placeholder":"​","style":"IPY_MODEL_57d19a0d3374433fbaa9a4864a5dc785","value":" 2961/2961 [00:00&lt;00:00, 3599.02it/s]"}},"72947257ead14d3e88ff7009863248d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"772dd409ba634e01985bd48c83660dac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7be27541d2d84f35be56254d89c537fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce05b0030c149edbd214e85302f51bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_f320bc899b3e4a8e97797834939ffa7d","style":"IPY_MODEL_2a30f66860354787b938f061b71607e1","tooltip":""}},"7e71872b758c40e0ab382a7be92783c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82abefcca1cb420eb35ed80b39784f41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdc5c40fb9a743e3b8119cd1016ef360","placeholder":"​","style":"IPY_MODEL_f7ecaaa1632b4bd083baf5c8079abcda","value":" 18395/18395 [00:02&lt;00:00, 6119.29it/s]"}},"866405fbab3f4c3d8dbdd8cfeb56c2a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ee04e2a9c40405ab4b644c3a0d91e32","max":2961,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b54f2ca89d24952b18a63514831a917","value":2961}},"86717084df6f489cbd9298cd88719792":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62f1cd7e72fc4cfbbd199e0c07c7df47","IPY_MODEL_6ff999d7df8c47cf88466896c19b4bae","IPY_MODEL_db37cf3a214a451abd24dc33150bb06f"],"layout":"IPY_MODEL_f39d17df86a64e19a8bb73b8c539858b"}},"882d0c484b504dd8b81a838ecba2a0d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88e0a60b35a546349947ce38c5763f43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e43d3ba53b141a0a1f0ede60171f0c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f1fd636e20246c2bf8e147b1cea750d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_ae4f94c1b36a4150b3f6bbf2c951febc","placeholder":"​","style":"IPY_MODEL_3f630911735946f0854eee7777340c1f","value":""}},"90df9cac606a4888afaa01b609b1c9a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"990abad8b2ab448bb531af1189c17b93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_081642fe533746a2b5e9966e1b81280a","placeholder":"​","style":"IPY_MODEL_392fe36405274793ae4e4b803bf12930","value":"Map:  11%"}},"9b54f2ca89d24952b18a63514831a917":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ca2f786074d4aef94fd75eea7bd93bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5cb1b700294e59b2424b577e686f4a","placeholder":"​","style":"IPY_MODEL_c32a7375adb1474a8e2ad9f24d043a62","value":" 532/4709 [00:18&lt;01:56, 35.86 examples/s]"}},"9e88b7b2010245a8ad504ae32fd7b059":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f079f19acaf44fabba70c32f146776a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc733ecedca749f18ef7a3f9387f7a05","placeholder":"​","style":"IPY_MODEL_187f57f867764d6790604cf6b2f3b58f","value":"Your token has been saved in your configured git credential helpers (store)."}},"a373abfce8ff442e9cb379a2623982d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5425af01d834bdaad3e3b43ca2c2e57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a60c757a35ee4733b62827ca5663d274":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0be5ccd757d45e697926215509e4b37","placeholder":"​","style":"IPY_MODEL_dcb012679bc444c4a9cda5c16201b0bd","value":"Resolving data files: 100%"}},"a862a0a40dd14543a89616d43fdc6963":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae4f94c1b36a4150b3f6bbf2c951febc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0be5ccd757d45e697926215509e4b37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0be6b32664a48d683a70bef051c4913":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e43d3ba53b141a0a1f0ede60171f0c1","placeholder":"​","style":"IPY_MODEL_882d0c484b504dd8b81a838ecba2a0d8","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"b27d5e5d652d4f8f9cf85061721173f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8fb7b52e9bf4b5b989dfb8cff8c09b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9ed46b759e24d1b8d16e03ed6873e77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc6c07e90a824852871314c2edde98d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_437e2e325d544583815863c57bda5e62","placeholder":"​","style":"IPY_MODEL_121cf9cbc169466b94490d731dd39dbd","value":"Your token has been saved to /root/.cache/huggingface/token"}},"bdc5c40fb9a743e3b8119cd1016ef360":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0a1b30cf6fc4fca86b5924a396f7bea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0b51deca5394b09bc9493a0af5dad99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c32a7375adb1474a8e2ad9f24d043a62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3e296ca2e94465cb75177cadeb23000":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee6312bfc515403f8f3a1c00d7cfff13","max":2960,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5425af01d834bdaad3e3b43ca2c2e57","value":2960}},"c5377555f58d47b7b5d817ab6acdcb5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e71872b758c40e0ab382a7be92783c1","placeholder":"​","style":"IPY_MODEL_fdbc3606add844c4993fb2efc15dac8a","value":"Resolving data files: 100%"}},"cc733ecedca749f18ef7a3f9387f7a05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf5a1711cdb34cbd9905a7c615d0c44f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e88b7b2010245a8ad504ae32fd7b059","placeholder":"​","style":"IPY_MODEL_a373abfce8ff442e9cb379a2623982d6","value":"Token is valid (permission: write)."}},"d1e8e77f22574140b9e41f16b0a3096c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3771b128d314796bbd2185ce8a6bc8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d48c12fabf024a9faeb0e255a409703a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d81db4c8bc5c4d998e5d20484bfd6bbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db37cf3a214a451abd24dc33150bb06f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_195344ba0fc646a6b995d3f7008d9374","placeholder":"​","style":"IPY_MODEL_deb4a89c071f40a7ae5be44c07f19b3e","value":" 11277/11277 [08:34&lt;00:00, 28.63 examples/s]"}},"dcb012679bc444c4a9cda5c16201b0bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deb4a89c071f40a7ae5be44c07f19b3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9775d8127bf4f15bccaaa5755748c55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f31da1d4e57b43088adc1acf5e8d4af6","max":4709,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b27d5e5d652d4f8f9cf85061721173f1","value":532}},"eb8b42bd68404979bf76f124e6c99f1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee6312bfc515403f8f3a1c00d7cfff13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c985a5eb19488ba265cf85ab24307b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8fb7b52e9bf4b5b989dfb8cff8c09b6","placeholder":"​","style":"IPY_MODEL_772dd409ba634e01985bd48c83660dac","value":"Connecting..."}},"f31da1d4e57b43088adc1acf5e8d4af6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f320bc899b3e4a8e97797834939ffa7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f39d17df86a64e19a8bb73b8c539858b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46b38f981644b4ea29c20c5c6fcf587":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d133e8bf07641e1aeac089ab2cf4313","placeholder":"​","style":"IPY_MODEL_fd60ce691e0343ec9ec18d844b22a3f4","value":"Login successful"}},"f79021fd9e8c40d99bb10c3fe025f4ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"f7ecaaa1632b4bd083baf5c8079abcda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f913068592dd4fd1a9b3a73284f91672":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4af9d1a937f746948e3f915e06c5ad11","IPY_MODEL_5fab8669bb1141089b5d9a92a2985820","IPY_MODEL_36b8688ee1a54b3aa161f0b8388ba225"],"layout":"IPY_MODEL_5725dfe3994c489ca94fefb0cd058afb"}},"fa6fb1445752440487816a1ebd3398a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd60ce691e0343ec9ec18d844b22a3f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdbc3606add844c4993fb2efc15dac8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}
